{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsnd8ck9-JhU"
   },
   "source": [
    "# Przetwarzanie języka naturalnego\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5uQlTHTHN4r"
   },
   "source": [
    "## Wstęp\n",
    "\n",
    "Obecnie najpopularniejsze model służące do przetwarzania języka naturalnego wykorzystują architekturę transformacyjną. Istnieje kilka bibliotek, implementujących tę architekturę, ale w kontekście NLP najczęściej wykorzystuje się [Huggingface transformers](https://huggingface.co/docs/transformers/index).\n",
    "\n",
    "Biblioteka ta poza samym [kodem źródłowym](https://github.com/huggingface/transformers), zawiera szereg innych elementów. Do najważniejszych z nich należą:\n",
    "* [modele](https://huggingface.co/models) - olbrzymia i ciągle rosnąca liczba gotowych modeli, których możemy użyć do rozwiązywania wielu problemów z dziedziny NLP (ale również w zakresie rozpoznawania mowy, czy przetwarzania obrazu),\n",
    "* [zbiory danych](https://huggingface.co/datasets) - bardzo duży katalog przydatnych zbiorów danych, które możemy w prosty sposób wykorzystać do trenowania własnych modeli NLP (oraz innych modeli)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCVKT9diUlqT"
   },
   "source": [
    "## Weryfikacja dostępności GPU\n",
    "\n",
    "Trening modeli NLP wymaga dostępu do akceleratorów sprzętowych, przyspieszających uczenie sieci neuronowych. Jeśli nasz komputer nie jest wyposażony w GPU, to możemy skorzystać ze środowiska Google Colab.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/apohllo/sztuczna-inteligencja/blob/master/lab5/lab_5.ipynb)\n",
    "\n",
    "W tym środowisku możemy wybrać akcelerator spośród GPU i TPU.\n",
    "\n",
    "Sprawdźmy, czy mamy dostęp do środowiska wyposażonego w akcelerator NVidii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:15:20.965725Z",
     "iopub.status.busy": "2025-01-19T18:15:20.964723Z",
     "iopub.status.idle": "2025-01-19T18:15:21.188340Z",
     "shell.execute_reply": "2025-01-19T18:15:21.188340Z",
     "shell.execute_reply.started": "2025-01-19T18:15:20.965725Z"
    },
    "id": "G8OgLsVgK0bK",
    "outputId": "b7af210f-99d0-40eb-febb-230e98a17e9c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 19 19:15:21 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti   WDDM  |   00000000:07:00.0  On |                  N/A |\n",
      "|  0%   39C    P8             12W /  165W |     989MiB /  16380MiB |      4%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3872    C+G   ...\\PowerToys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A      4560    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      7264    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A      8300    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9992    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     11716    C+G   ...up\\ui-launcher\\AdskAccessUIHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13836    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     14760    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15300    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     16736    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     18536    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     19424    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     19916    C+G   ...n\\131.0.2903.146\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19952    C+G   D:\\overwolf\\old_Overwolf.exe                N/A      |\n",
      "|    0   N/A  N/A     20312    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     20508    C+G   ...wolf\\0.266.1.26\\OverwolfBrowser.exe      N/A      |\n",
      "|    0   N/A  N/A     20696    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     21140    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     22372    C+G   ..._x64__cw5n1h2txyewy\\WidgetBoard.exe      N/A      |\n",
      "|    0   N/A  N/A     22484    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     23072    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     24656    C+G   ...werToys\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A     26244    C+G   ...35.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     26532    C+G   ...al\\Discord\\app-1.0.9177\\Discord.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iHWHwumLJy-"
   },
   "source": [
    "Jeśli akcelerator jest niedostępny (polecenie skończyło się błędem), to zmieniamy środowisko wykonawcze wybierając z menu \"Środowisko wykonawcze\" -> \"Zmień typ środowiska wykonawczego\" -> GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTXP41EDFoA4"
   },
   "source": [
    "## Podpięcie dysku Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qXbT070FoA4"
   },
   "source": [
    "Kolejnym elementem przygotowań, który jest opcjonalny, jest dołączenie własnego dysku Google Drive do środowiska Colab. Dzięki temu możliwe jest zapisywanie wytrenowanych modeli, w trakcie procesu treningu, na \"zewnętrznym\" dysku. Jeśli Google Colab doprowadzi do przerwania procesu treningu, to mimo wszystko pliki, które udało się zapisać w trakcie treningu nie przepadną. Możliwe będzie wznowienie treningu już na częściowo wytrenowanym modelu.\n",
    "\n",
    "W tym celu montujemy dysk Google w Colabie. Wymaga to autoryzacji narzędzia Colab w Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-13T11:01:10.422451Z",
     "start_time": "2023-01-13T11:01:09.790725Z"
    },
    "id": "ysEoT8AhFoA4",
    "outputId": "f9116535-35d9-4eed-e851-b42037e1c76b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grytPGtiFoA4"
   },
   "source": [
    "Po podmontowaniu dysku mamy dostęp do całej zawartości Google Drive. Wskazując miejsce zapisywania danych w trakcie treningu należy wskazać ścieżkę zaczynającą się od `/content/gdrive`, ale należy wskazać jakiś podkatalog w ramach naszej przestrzeni dyskowej. Pełna ścieżka może mieć postać `/content/gdrive/MyDrive/output`. Przed uruchomieniem treningu warto sprawdzić, czy dane zapisują się na dysku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubd7LV7kI3wo"
   },
   "source": [
    "## Instalacja bibliotek Pythona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ_GoQx_K6sC"
   },
   "source": [
    "Następnie zainstalujemy wszystkie niezbędne biblioteki.\n",
    "Poza samą biblioteką `transformers`, instalujemy również biblioteki do zarządzania zbiorami danych `datasets`, bibliotekę definiującą wiele metryk wykorzystywanych w algorytmach AI `evaluate` oraz dodatkowe narzędzia takie jak `sacremoses` oraz `sentencepiece`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:15:47.910651Z",
     "iopub.status.busy": "2025-01-19T18:15:47.909641Z",
     "iopub.status.idle": "2025-01-19T18:16:57.161909Z",
     "shell.execute_reply": "2025-01-19T18:16:57.161909Z",
     "shell.execute_reply.started": "2025-01-19T18:15:47.910651Z"
    },
    "id": "eeJtMsvBJ48f",
    "outputId": "8693a6df-7e23-4a54-c445-271558041468",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.35.2\n",
      "  Obtaining dependency information for transformers==4.35.2 from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "     ---------------------------------------- 0.0/123.5 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 20.5/123.5 kB 320.0 kB/s eta 0:00:01\n",
      "     ------------ ------------------------ 41.0/123.5 kB 487.6 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 102.4/123.5 kB 737.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ 123.5/123.5 kB 906.0 kB/s eta 0:00:00\n",
      "Collecting sacremoses==0.1.1\n",
      "  Obtaining dependency information for sacremoses==0.1.1 from https://files.pythonhosted.org/packages/0b/f0/89ee2bc9da434bd78464f288fdb346bc2932f2ee80a90b2a4bbbac262c74/sacremoses-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting datasets==2.15.0\n",
      "  Obtaining dependency information for datasets==2.15.0 from https://files.pythonhosted.org/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting evaluate==0.4.1\n",
      "  Obtaining dependency information for evaluate==0.4.1 from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting sentencepiece==0.1.99\n",
      "  Obtaining dependency information for sentencepiece==0.1.99 from https://files.pythonhosted.org/packages/cc/07/d6951e3b4079df819d76353302fc3e76835252e7e0b6366f96a03d87ea5f/sentencepiece-0.1.99-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting accelerate==0.24.1\n",
      "  Obtaining dependency information for accelerate==0.24.1 from https://files.pythonhosted.org/packages/13/9e/ee987874058f2d93006961f6ff49e0bcb60ab9c26709ebe06bfa8707a4d8/accelerate-0.24.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/6c/3f/50f6b25fafdcfb1c089187a328c95081abf882309afd86f4053951507cd1/huggingface_hub-0.27.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/c1/02/40725eebedea8175918bd59ab80b2174d6ef3b3ef9ac8ec996e84c38d3ca/tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\anaconda3\\lib\\site-packages (from transformers==4.35.2) (4.65.0)\n",
      "Requirement already satisfied: click in e:\\anaconda3\\lib\\site-packages (from sacremoses==0.1.1) (8.0.4)\n",
      "Requirement already satisfied: joblib in e:\\anaconda3\\lib\\site-packages (from sacremoses==0.1.1) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (11.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.15.0)\n",
      "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (2.0.3)\n",
      "Requirement already satisfied: xxhash in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in e:\\anaconda3\\lib\\site-packages (from datasets==2.15.0) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in e:\\anaconda3\\lib\\site-packages (from evaluate==0.4.1) (0.13.3)\n",
      "Requirement already satisfied: psutil in e:\\anaconda3\\lib\\site-packages (from accelerate==0.24.1) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in e:\\anaconda3\\lib\\site-packages (from accelerate==0.24.1) (2.5.1+cu118)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.15.0) (1.2.0)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/61/8c/fbdc0a88a622d9fa54e132d7bf3ee03ec602758658a2db5b339a65be2cfe/huggingface_hub-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/44/5a/dc6af87c61f89b23439eb95521e4e99862636cfd538ae12fd36be5483e5f/huggingface_hub-0.26.5-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/95/9b/3068fb3ae0b498eb66960ca5f4d92a81c91458cacd4dc17bfa6d40ce90fb/huggingface_hub-0.26.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/60/bf/cea0b9720c32fa01b0c4ec4b16b9f4ae34ca106b202ebbae9f03ab98cd8f/huggingface_hub-0.26.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/d7/4d/017d8d7cff5100092da8ea19139bcb1965bbadcbb5ddd0480e2badc299e8/huggingface_hub-0.26.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/85/1f/21e2fb9564b53122105866c26daeb239911b003d1df3867dd113cf5a7694/huggingface_hub-0.26.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/64/09/a535946bf2dc88e61341f39dc507530411bb3ea4eac493e5ec833e8f35bd/huggingface_hub-0.25.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/5f/f1/15dc793cb109a801346f910a6b350530f2a763a6e83b221725a0bcc1e297/huggingface_hub-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/d5/ce/1f8e61cd63175cc2e79233b954b1c4e85363c788fb3a1fa23c87a25c9b81/huggingface_hub-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/57/28/a0b0dd3cca63908045edc300360d6cd8758d4d86eee3fd2b08f00c5a41c4/huggingface_hub-0.24.7-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/b9/8f/d6718641c14d98a5848c6a24d2376028d292074ffade0702940a4b1dde76/huggingface_hub-0.24.6-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/0b/05/31b21998f68c31e7ffcc27ff08531fb9af5506d765ce8d661fb0036e6918/huggingface_hub-0.24.5-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/24/e6/25bf55a201ee15aed4e87dc4ff1182436986ea6ffd97a941aeacf8d559ab/huggingface_hub-0.24.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/0f/36/83c0f0c7a5ec75738241c4c0c066097e4f74729716961db6a2905395015c/huggingface_hub-0.24.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/93/14/6a82b1c2eab5a828f7d3d675811660eb68424e8b039191f418a94e8d9726/huggingface_hub-0.24.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/96/e6/a1fd9cccd2c08244243aeef71b61cb9b2ba26575d8fd6f7c41edc95e9de0/huggingface_hub-0.24.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/57/c0/cf4435f3186655e3bafdca08cd6c794e3866f1f89ed99595504e7240b6a2/huggingface_hub-0.24.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/2a/6e/46c71094566fe58663bd661a8ce11c26b25d717a11ed8289f6b94ad72a3b/huggingface_hub-0.23.5-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/69/d6/73f9d1b7c4da5f0544bc17680d0fa9932445423b90cd38e1ee77d001a4f5/huggingface_hub-0.23.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/66/e8/bbbad5c7b49c68def42830f96c606e693bfa935a886740a363f04cb84e44/huggingface_hub-0.23.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/78/71/6ce4136149cb42b98599d49c39b3a39dd6858b5f9307490998c40e26a51e/huggingface_hub-0.23.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/92/27/1a30d8082ef3c8615ae198b9d451fafffdab815b96727ec3c06befc27ebe/huggingface_hub-0.23.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/21/2b/516f82c5ba9beb184b24c11976be2ad5e80fb7fe6b2796c887087144445e/huggingface_hub-0.23.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/b6/51/d418bb7bb9e32845d3cb4d526012ddf1fea6bb3d55b6a1880698e4b7f19f/huggingface_hub-0.22.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.22.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/89/66/1e0799583d8c844b59aa1a1d06ba26d50e8748d8b61b3ba8cbe4a0b26bc0/huggingface_hub-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.22.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/ab/28/d4b691840d73126d4c9845f8a22dad033ac872509b6d3a0d93b456eef424/huggingface_hub-0.21.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/47/8f/cf6683de320cf3873850ba48b7383db96958fe435b8e227db92119f6d867/huggingface_hub-0.21.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/3d/c8/c3342c97848896df5d78d18abd94c558e457a4f02feec99a79989d8c30e0/huggingface_hub-0.21.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/15/95/614f1a310e333e9bbf338bcc3c9378aa4c5ae7978b8621c934e27ce6befc/huggingface_hub-0.21.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/76/4d/8def98a3925c1e3a1b26eebdcf21ebc25e997b9ce85fd1c88290104b9ae5/huggingface_hub-0.21.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/28/03/7d3c7153113ec59cfb31e3b8ee773f5f420a0dd7d26d40442542b96675c3/huggingface_hub-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/3d/0a/aed3253a9ce63d9c90829b1d36bc44ad966499ff4f5827309099c8c9184b/huggingface_hub-0.20.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/a0/0a/02ac0ae1047d97769003ff4fb8e6717024f3f174a5d13257415aa09e13d9/huggingface_hub-0.20.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/69/03/46f112e2e415926bc7bdac2f5366572de0c28cb88051537b25a586b5d881/huggingface_hub-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/38/f6/06d7489a9f1b2112a640b3272abd43319d0ee625f26efafb350106893c19/huggingface_hub-0.19.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.3-py3-none-any.whl.metadata (14 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/38/ea/01fab9eaff633d522d84fc76c6973873abbd54baafba03bf5992c8ef144a/huggingface_hub-0.19.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/65/cc/2891260847777eb9aaca278aaf3f846c9ff8ea1351643a4f33ff26d5d213/huggingface_hub-0.19.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/64/8c/2766ce7e136eeb8b4d502e68eb1fe65342ee1aaf9129ec1c0838e5a4f0cb/huggingface_hub-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets==2.15.0)\n",
      "  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->transformers==4.35.2) (2023.7.22)\n",
      "Requirement already satisfied: six in e:\\anaconda3\\lib\\site-packages (from responses<0.19->evaluate==0.4.1) (1.16.0)\n",
      "Requirement already satisfied: networkx in e:\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.24.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.24.1) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.35.2) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda3\\lib\\site-packages (from pandas->datasets==2.15.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\lib\\site-packages (from pandas->datasets==2.15.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\anaconda3\\lib\\site-packages (from pandas->datasets==2.15.0) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.24.1) (2.1.1)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.9 MB 9.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.9/7.9 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/7.9 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.1/7.9 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/7.9 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.0/7.9 MB 22.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.7/7.9 MB 24.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 15.3 MB/s eta 0:00:00\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "   ---------------------------------------- 0.0/897.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 897.5/897.5 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "   ---------------------------------------- 0.0/521.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 521.2/521.2 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.1/84.1 kB ? eta 0:00:00\n",
      "Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "   ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n",
      "   --------------------------------------  972.8/977.5 kB 60.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 977.5/977.5 kB 20.6 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "   ---------------------------------------- 0.0/261.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 261.4/261.4 kB 16.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "   ---------------------------------------- 0.0/450.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 450.7/450.7 kB 14.2 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  163.8/166.4 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 166.4/166.4 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 42.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 46.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 46.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 46.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: sentencepiece, pyarrow-hotfix, fsspec, sacremoses, huggingface-hub, tokenizers, accelerate, transformers, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.12.0\n",
      "    Uninstalling datasets-2.12.0:\n",
      "      Successfully uninstalled datasets-2.12.0\n",
      "Successfully installed accelerate-0.24.1 datasets-2.15.0 evaluate-0.4.1 fsspec-2023.10.0 huggingface-hub-0.27.1 pyarrow-hotfix-0.6 sacremoses-0.1.1 sentencepiece-0.1.99 tokenizers-0.15.2 transformers-4.35.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2023.10.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.35.2 sacremoses==0.1.1 datasets==2.15.0 evaluate==0.4.1 sentencepiece==0.1.99 accelerate==0.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJunO6pV_tRK"
   },
   "source": [
    "Mając zainstalowane niezbedne bilioteki, możemy skorzystać z wszystkich modeli i zbiorów danych zarejestrowanych w katalogu.\n",
    "\n",
    "Typowym sposobem użycia dostępnych modeli jest:\n",
    "* *wykorzystanie gotowego modelu*, który realizuje określone zadanie, np. [analizę senetymentu w języku angielskim](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis) - model tego rodzaju nie musi być trenowywany, wystarczy go uruchomić aby uzyskać wynik klasyfikacji (można to zobaczyć w demo pod wskazanym linkiem),\n",
    "* *wykorzystanie modelu bazowego*, który jest dotrenowywany do określonego zadania; przykładem takiego modelu jest [HerBERT base](https://huggingface.co/allegro/herbert-base-cased), który uczony był jako maskowany model języka. Żeby wykorzystać go do konkretnego zadania, musimy wybrać dla niego \"głowę klasyfikacyjną\" oraz dotrenować na własnym zbiorze danych.\n",
    "\n",
    "Modele tego rodzaju różnią się od siebie, można je załadować za pomocą wspólnego interfejsu, ale najlepiej jest wykorzystać jedną ze specjalizowanych klas, dostosowanych do zadania, które chcemy zrealizować. Zaczniemy od załadowania modelu BERT base - jednego z najbardziej popularnych modeli, dla języka angielskiego. Za jego pomocą będziemy odgadywać brakujące wyrazy w tekście. Wykorzystamy do tego wywołanie `AutoModelForMaskedLM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:19:44.499726Z",
     "iopub.status.busy": "2025-01-19T18:19:44.499726Z",
     "iopub.status.idle": "2025-01-19T18:20:47.491337Z",
     "shell.execute_reply": "2025-01-19T18:20:47.491337Z",
     "shell.execute_reply.started": "2025-01-19T18:19:44.499726Z"
    },
    "id": "wTCDkZ1nKIEm",
    "outputId": "7bc53054-0acc-45d6-fb41-ad63296d1580",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "E:\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a129d7a76a84595a48cf58db54f8219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kacpe\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "E:\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "E:\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "E:\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f3d9df648d42079c6818eb20c0a198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCHU5ArMJZfC"
   },
   "source": [
    "Załadowany model jest modułem PyTorcha. Możemy zatem korzystać z API tej biblioteki. Możemy np. sprawdzić ile parametrów ma model BERT base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:21:21.647748Z",
     "iopub.status.busy": "2025-01-19T18:21:21.646748Z",
     "iopub.status.idle": "2025-01-19T18:21:21.654385Z",
     "shell.execute_reply": "2025-01-19T18:21:21.654385Z",
     "shell.execute_reply.started": "2025-01-19T18:21:21.647748Z"
    },
    "id": "M-dS04e4JX4x",
    "outputId": "2531e1fb-b619-400f-e1da-0a961fbe8baa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'108 340 804'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "'{:,}'.format(count).replace(',', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9aPClBxKEWq"
   },
   "source": [
    "Widzimi zatem, że nasz model jest bardzo duży - zawiera ponad 100 milionów parametrów, a jest to tzw. model bazowy. Modele obecnie wykorzystywane mają jeszcze więcej parametrów - duże modele językowe, takie jak ChatGPT posiadają więcej niż 100 miliardów parametrów.\n",
    "\n",
    "Możemy również podejrzeć samą strukturę modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:21:24.248486Z",
     "iopub.status.busy": "2025-01-19T18:21:24.248486Z",
     "iopub.status.idle": "2025-01-19T18:21:24.254966Z",
     "shell.execute_reply": "2025-01-19T18:21:24.254966Z",
     "shell.execute_reply.started": "2025-01-19T18:21:24.248486Z"
    },
    "id": "TqCH8YrzKguC",
    "outputId": "b3f539b1-b29e-4186-a38d-e1bb73bf8d43",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdgyGz752126"
   },
   "source": [
    "# Tokenizacja tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmX8eu_mB9CO"
   },
   "source": [
    "Załadowanie samego modelu nie jest jednak wystarczające, żeby zacząć go wykorzystywać. Musimy mieć mechanizm zamiany tekstu (łańcucha znaków), na ciąg tokenów, należących do określonego słownika. W trakcie treningu modelu, słownik ten jest określany (wybierany w sposób algorytmiczny) przed właściwym treningiem sieci neuronowej. Choć możliwe jest jego późniejsze rozszerzenie (douczenie na danych treningowych, pozwala również uzyskać reprezentację brakujących tokenów), to zwykle wykorzystuje się słownik w postaci, która została określona przed treningiem sieci neuronowej. Dlatego tak istotne jest wskazanie właściwego słownika dla tokenizera dokonującego podziału tekstu.\n",
    "\n",
    "Biblioteka posiada klasę `AutoTokenizer`, która akceptuje nazwę modelu, co pozwala automatycznie załadować słownik korespondujący z wybranym modelem sieci neuronowej. Trzeba jednak pamiętać, że jeśli używamy 2 modeli, to każdy z nich najpewniej będzie miał inny słownik, a co za tym idzie muszą one mieć własne instancje klasy `Tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:22:17.548841Z",
     "iopub.status.busy": "2025-01-19T18:22:17.548841Z",
     "iopub.status.idle": "2025-01-19T18:22:19.442500Z",
     "shell.execute_reply": "2025-01-19T18:22:19.442500Z",
     "shell.execute_reply.started": "2025-01-19T18:22:17.548841Z"
    },
    "id": "PYUsVa1fBTPW",
    "outputId": "a868fa3a-ed91-4319-b0bb-25d2917dd1f3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99273ae69674464be4643567f9ab600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf68509246d48e6ada4b844784d92df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfa9c7d2e7340bcbd67db8a62f51740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXIePLylEFx2"
   },
   "source": [
    "Tokenizer posługuje się słownikiem o stałym rozmiarze. Podowuje to oczywiście, że nie wszystkie wyrazy występujące w tekście, będą się w nim znajdowały. Co więcej, jeśli użyjemy tokenizera do podziału tekstu w innym języku, niż ten dla którego został on stworzony, to taki tekst będzie dzielony na większą liczbę tokenów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:23:26.858727Z",
     "iopub.status.busy": "2025-01-19T18:23:26.857724Z",
     "iopub.status.idle": "2025-01-19T18:23:26.876408Z",
     "shell.execute_reply": "2025-01-19T18:23:26.876408Z",
     "shell.execute_reply.started": "2025-01-19T18:23:26.858727Z"
    },
    "id": "DAGb1Jzhtr9p",
    "outputId": "4b910774-f2e7-4c85-bab5-16f7753a528c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1109,  3613,  3058, 17594, 15457,  1166,  1103, 16688,  3676,\n",
      "           119,   102]])\n",
      "torch.Size([1, 12])\n",
      "tensor([[  101,   163,  1161, 28259,  7774, 20671,  7128,   176, 28221, 28244,\n",
      "          1233, 28213,   179,  1161, 28257, 19339,   119,   102]])\n",
      "torch.Size([1, 18])\n"
     ]
    }
   ],
   "source": [
    "sentence1 = tokenizer.encode(\n",
    "    \"The quick brown fox jumps over the lazy dog.\", return_tensors=\"pt\"\n",
    ")\n",
    "print(sentence1)\n",
    "print(sentence1.shape)\n",
    "\n",
    "sentence2 = tokenizer.encode(\"Zażółć gęślą jaźń.\", return_tensors=\"pt\")\n",
    "print(sentence2)\n",
    "print(sentence2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ILQRogoErrt"
   },
   "source": [
    "Korzystająć z tokenizera dla języka angielsiego do podziału polskiego zdania, widzimy, że otrzymujemy znacznie większą liczbę tokenów. Żeby zobaczyć, w jaki sposób tokenizer dokonał podziału tekstu, możemy wykorzystać wywołanie `covert_ids_to_tokens`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:37:22.570321Z",
     "iopub.status.busy": "2025-01-19T18:37:22.569321Z",
     "iopub.status.idle": "2025-01-19T18:37:22.575517Z",
     "shell.execute_reply": "2025-01-19T18:37:22.575517Z",
     "shell.execute_reply.started": "2025-01-19T18:37:22.570321Z"
    },
    "id": "DOnw6mq81QFg",
    "outputId": "37e7ae97-0b4d-4c4d-ccde-ba7852c10510",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]|The|quick|brown|fox|jumps|over|the|lazy|dog|.|[SEP]\n",
      "[CLS]|Z|##a|##ż|##ó|##ł|##ć|g|##ę|##ś|##l|##ą|j|##a|##ź|##ń|.|[SEP]\n"
     ]
    }
   ],
   "source": [
    "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(sentence1[0]))))\n",
    "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(sentence2[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZzt3-w5GQDB"
   },
   "source": [
    "Widzimy, że dla jęzka angielskiego wszystkie wyrazy w zdaniu zostały przekształcone w pojedyncze tokeny. W przypadku zdania w języku polskim, zawierającego szereg znaków diakrytycznych sytuacja jest zupełnie inna - każdy znak został wyodrębniony do osobnego sub-tokenu. To, że mamy do czynienia z sub-tokenami sygnalizowane jest przez dwa krzyżyki poprzedzające dany sub-token. Oznaczają one, że ten sub-token musi być sklejony z porzedzającym go tokenem, aby uzyskać właściwy łańcuch znaków.\n",
    "\n",
    "## Zadanie 1 (0.5 punkt)\n",
    "\n",
    "Wykorzystaj tokenizer dla modelu `allegro/herbert-base-cased`, aby dokonać tokenizacji tych samych zdań. Jakie wnioski można wyciągnąć przyglądając się sposobowi tokenizacji za pomocą różnych słowników?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T13:58:00.312979Z",
     "start_time": "2022-12-20T13:58:00.303639Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-19T18:39:07.560076Z",
     "iopub.status.busy": "2025-01-19T18:39:07.559074Z",
     "iopub.status.idle": "2025-01-19T18:39:07.865076Z",
     "shell.execute_reply": "2025-01-19T18:39:07.865076Z",
     "shell.execute_reply.started": "2025-01-19T18:39:07.560076Z"
    },
    "id": "qEir3EhlHHaQ",
    "outputId": "adef2677-a426-4f8a-aa4a-41677b5a3455",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  7117, 22991,  4879, 25015,  1016,  3435,  1055,  2202,  4952,\n",
      "          1010,    83, 10259,  6854,  2050,  3852,  2065,  1031,  1899,     2]])\n",
      "torch.Size([1, 20])\n",
      "tensor([[    0,  2237,  7227,  1048,  7029, 46389,  2059,   272,  1059,  1899,\n",
      "             2]])\n",
      "torch.Size([1, 11])\n",
      "<s>|The</w>|qui|ck</w>|brow|n</w>|fo|x</w>|ju|mp|s</w>|o|ver</w>|the</w>|la|zy</w>|do|g</w>|.</w>|</s>\n",
      "<s>|Za|żół|ć</w>|gę|ślą</w>|ja|ź|ń</w>|.</w>|</s>\n"
     ]
    }
   ],
   "source": [
    "# your_code\n",
    "tokenizer_allegro = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "sentence1 = tokenizer_allegro.encode(\n",
    "    \"The quick brown fox jumps over the lazy dog.\", return_tensors=\"pt\"\n",
    ")\n",
    "print(sentence1)\n",
    "print(sentence1.shape)\n",
    "\n",
    "sentence2 = tokenizer_allegro.encode(\"Zażółć gęślą jaźń.\", return_tensors=\"pt\")\n",
    "print(sentence2)\n",
    "print(sentence2.shape)\n",
    "\n",
    "print(\"|\".join(tokenizer_allegro.convert_ids_to_tokens(list(sentence1[0]))))\n",
    "print(\"|\".join(tokenizer_allegro.convert_ids_to_tokens(list(sentence2[0]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US-hA9UMOPk_"
   },
   "source": [
    "Tokenizer od allegro lepiej radzi sobie z językiem polskim, dlatego, że najprawopdobniej był na nim douczany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJquTQTDHLQY"
   },
   "source": [
    "W wynikach tokenizacji poza wyrazami/tokenami występującymi w oryginalnym tekście pojawiają się jeszcze dodatkowe znaczniki `[CLS]` oraz `[SEP]` (albo inne znaczniki - w zależności od użytego słownika). Mają one specjalne znaczenie i mogą być wykorzystywane do realizacji specyficznych funkcji związanych z analizą tekstu. Np. reprezentacja tokenu `[CLS]` wykorzystywana jest w zadaniach klasyfikacji zdań. Z kolei token `[SEP]` wykorzystywany jest do odróżnienia zdań, w zadaniach wymagających na wejściu dwóch zdań (np. określenia, na ile zdania te są podobne do siebie).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFR6OfWBU0TP"
   },
   "source": [
    "# Modelowanie języka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2dVbEVuOoy1"
   },
   "source": [
    "Modele pretrenowane w reżimie self-supervised learning (SSL) nie posiadają specjalnych zdolności w zakresie rozwiązywania konkretnych zadań z zakresu przetwarzania języka naturalnego, takich jak odpowiadanie na pytania, czy klasyfikacja tekstu (z wyjątkiem bardzo dużych modeli, takich jak np. GPT-3, których model językowy zdolny jest do predykcji np. sensownych odpowiedzi na pytania). Można je jednak wykorzystać do określania prawdopodobieństwa wyrazów w tekście, a tym samym do sprawdzenia, jaką wiedzę posiada określony model w zakresie znajomości języka, czy też ogólną wiedzę o świecie.\n",
    "\n",
    "Aby sprawdzić jak model radzi sobie w tych zadaniach, możemy dokonać inferencji na danych wejściowych, w których niektóre wyrazy zostaną zastąpione specjalnymi symbolami maskującymi, wykorzystywanymi w trakcie pre-treningu modelu.\n",
    "\n",
    "Należy mieć na uwadze, że różne modele mogą korzystać z różnych specjalnych sekwencji w trakcie pretreningu. Np. Bert korzysta z sekwencji `[MASK]`. Wygląd tokenu maskującego lub jego identyfikator możemy sprawdzić w [pliku konfiguracji tokenizera](https://huggingface.co/bert-base-cased/raw/main/tokenizer.json) dystrubowanym razem z modelem, albo odczytać wprost z instancji tokenizera.\n",
    "\n",
    "W pierwszej kolejności, spróbujemy uzupełnić brakujący wyraz w angielskim zdaniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:41:45.375031Z",
     "iopub.status.busy": "2025-01-19T18:41:45.374025Z",
     "iopub.status.idle": "2025-01-19T18:41:45.639971Z",
     "shell.execute_reply": "2025-01-19T18:41:45.639971Z",
     "shell.execute_reply.started": "2025-01-19T18:41:45.375031Z"
    },
    "id": "YgV2T4C3xsaD",
    "outputId": "b10aff26-f9d3-4a8f-b73a-f78b89ce467c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]|The|quick|brown|[MASK]|jumps|over|the|lazy|dog|.|[SEP]\n",
      "tensor([-5.3489, -5.6063, -5.1303,  ..., -5.9625, -4.1559, -4.5403],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sentence_en = tokenizer.encode(\n",
    "    \"The quick brown [MASK] jumps over the lazy dog.\", return_tensors=\"pt\"\n",
    ")\n",
    "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(sentence_en[0]))))\n",
    "target = model(sentence_en)\n",
    "print(target.logits[0][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc5CfCfSRV5E"
   },
   "source": [
    "Ponieważ zdanie po stokenizowaniu uzupełniane jest znacznikiem `[CLS]`, to zamaskowane słowo znajduje się na 4 pozycji. Wywołanie `target.logits[0][4]` pokazuje tensor z rozkładem prawdopodobieństwa poszczególnych wyrazów, które zostało określone na podstawie parametrów modelu. Możemy wybrać wyrazy, które posiadają największe prawdopodobieństwo, korzystając z wywołania `torch.topk`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:42:07.442780Z",
     "iopub.status.busy": "2025-01-19T18:42:07.442780Z",
     "iopub.status.idle": "2025-01-19T18:42:07.453154Z",
     "shell.execute_reply": "2025-01-19T18:42:07.453154Z",
     "shell.execute_reply.started": "2025-01-19T18:42:07.442780Z"
    },
    "id": "C3ugmBzhz5uu",
    "outputId": "186e2120-a547-4e04-ac14-ec85571ba55b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([12.1982, 11.2289, 10.6009, 10.1278, 10.0120], grad_fn=<TopkBackward0>),\n",
       "indices=tensor([ 3676,  1663,  5855,  4965, 21566]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "top = torch.topk(target.logits[0][4], 5)\n",
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz5nw1LbR5Va"
   },
   "source": [
    "Otrzymaliśmy dwa wektory - `values` zawierający składowe wektora wyjściowego sieci neuronowej (nieznormalizowane) oraz `indices` zawierający indeksy tych składowych. Na tej podstawie możemy wyświetlić wyraz, które według modelu są najbardziej prawdopodobnymi uzupełnieniami zamaskowanego wyrazu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:42:11.170163Z",
     "iopub.status.busy": "2025-01-19T18:42:11.170163Z",
     "iopub.status.idle": "2025-01-19T18:42:11.173402Z",
     "shell.execute_reply": "2025-01-19T18:42:11.173402Z",
     "shell.execute_reply.started": "2025-01-19T18:42:11.170163Z"
    },
    "id": "kkZKTw0J2BUn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = tokenizer.convert_ids_to_tokens(top.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:42:11.962698Z",
     "iopub.status.busy": "2025-01-19T18:42:11.962698Z",
     "iopub.status.idle": "2025-01-19T18:42:13.292890Z",
     "shell.execute_reply": "2025-01-19T18:42:13.292890Z",
     "shell.execute_reply.started": "2025-01-19T18:42:11.962698Z"
    },
    "id": "kmDVEzZQ2Omz",
    "outputId": "6f25cbcd-5b9b-4323-aec6-794d9b000e5b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(words, top.values.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "792etHKPSZrx"
   },
   "source": [
    "Według modelu najbardziej prawdopodobnym uzupełnieniem brakującego wyrazu jest `dog` (a nie `fox`). Nieco zaskakujący może być drugi wyraz `##ie`, ale po dodaniu go do istniejącego tekstu otrzymamy zdanie: \"The quick brownie jumps over the lazy dog\", które również wydaje się sensowne (choć nieco zaskakujące)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QK7MybnTT-h"
   },
   "source": [
    "## Zadanie 2 (1.5 punkty)\n",
    "\n",
    "Wykorzystując model `allegro/herbert-base-cased` zaproponuj zdania z jednym brakującym wyrazem, weryfikujące zdolność tego modelu do:\n",
    "* odmiany przez polskie przypadki,\n",
    "* uwzględniania długodystansowych związków w tekście,\n",
    "* reprezentowania wiedzy o świecie.\n",
    "\n",
    "Dla każdego problemu wymyśl po 3 zdania sprawdzające i wyświetl predykcję dla 5 najbardziej prawdopodobnych wyrazów.\n",
    "\n",
    "Możesz wykorzystać kod z funkcji `plot_words`, który ułatwi Ci wyświetlanie wyników. Zweryfikuj również jaki token maskujący wykorzystywany jest w tym modelu. Pamiętaj również o załadowaniu modelu `allegro/herbert-base-cased`.\n",
    "\n",
    "Oceń zdolności modelu w zakresie wskazanych zadań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T13:58:13.903939Z",
     "start_time": "2022-12-20T13:58:13.886635Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-19T20:02:54.109579Z",
     "iopub.status.busy": "2025-01-19T20:02:54.109579Z",
     "iopub.status.idle": "2025-01-19T20:02:56.971643Z",
     "shell.execute_reply": "2025-01-19T20:02:56.971643Z",
     "shell.execute_reply.started": "2025-01-19T20:02:54.109579Z"
    },
    "id": "iy1RYqMvTKEe",
    "outputId": "b8c33f57-9ee4-42e9-e016-4d64f4806cb3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mask>\n",
      "<s>|Janek</w>|chciał</w>|kupić</w>|prezent</w>|dla</w>|swojej</w>|siostry</w>|,</w>|ale</w>|zapomniał</w>|,</w>|co</w>|ona</w>|lubi</w>|najbardziej</w>|.</w>|<mask>|powiedziała</w>|,</w>|że</w>|uwiel|bia</w>|niespodzi|an|k</w>|</s>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_words(sentence, word_model, word_tokenizer, mask=\"<mask>\"):\n",
    "    sentence = word_tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    tokens = word_tokenizer.convert_ids_to_tokens(list(sentence[0]))\n",
    "    print(\"|\".join(tokens))\n",
    "    target = word_model(sentence)\n",
    "    top = torch.topk(target.logits[0][tokens.index(mask)], 5)\n",
    "    words = word_tokenizer.convert_ids_to_tokens(top.indices)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.bar(words, top.values.detach().numpy())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# your_code\n",
    "model_pl = AutoModelForMaskedLM.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "tokenizer_pl = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "print(tokenizer_pl.mask_token)\n",
    "sentence_pl = \"Janek chciał kupić prezent dla swojej siostry, ale zapomniał, co ona lubi najbardziej. <mask> powiedziała, że uwielbia niespodziank\"\n",
    "plot_words(sentence_pl,model_pl,tokenizer_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0D3wjqU5E7s"
   },
   "source": [
    "Poprawnie odmienił przez przypadki oraz domyślił się, że chodzi o siostre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe3jkYN4X0K6"
   },
   "source": [
    "# Klasyfikacja tekstu\n",
    "\n",
    "Pierwszym zadaniem, które zrealizujemy korzystając z modelu HerBERT będzie klasyfikacja tekstu. Będzie to jednak dość nietypowe zadanie. O ile oczekiwanym wynikiem jest klasyfikacja binarna, czyli dość popularny typ klasyfikacji, o tyle dane wejściowe są nietypowe, gdyż są to pary: `(pytanie, kontekst)`. Celem algorytmu jest określenie, czy na zadane pytanie można odpowiedzieć na podstawie informacji znajdujących się w kontekście.\n",
    "\n",
    "Model tego rodzaju jest nietypowy, ponieważ jest to zadanie z zakresu klasyfikacji par tekstów, ale my potraktujemy je jak zadanie klasyfikacji jednego tekstu, oznaczając jedynie fragmenty tekstu jako `Pytanie:` oraz `Kontekst:`. Wykorzystamy tutaj zdolność modeli transformacyjnych do automatycznego nauczenia się tego rodzaju znaczników, przez co proces przygotowania danych będzie bardzo uproszczony.\n",
    "\n",
    "Zbiorem danych, który wykorzystamy do treningu i ewaluacji modelu będzie PoQUAD - zbiór inspirowany angielskim [SQuADem](https://rajpurkar.github.io/SQuAD-explorer/), czyli zbiorem zawierającym ponad 100 tys. pytań i odpowiadających im odpowiedzi. Zbiór ten powstał niedawno i jest jeszcze rozbudowywany. Zawiera on pytania, odpowiedzi oraz konteksty, na podstawie których można udzielić odpowiedzi.\n",
    "\n",
    "W dalszej części laboratorium skoncentrujemy się na problemie odpowiadania na pytania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJFq2RGgVArz"
   },
   "source": [
    "## Przygotowanie danych do klasyfikacji\n",
    "\n",
    "Przygotowanie danych rozpoczniemy od sklonowania repozytorium zawierającego pytania i odpowiedzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:03:29.027921Z",
     "iopub.status.busy": "2025-01-19T20:03:29.027921Z",
     "iopub.status.idle": "2025-01-19T20:03:49.108592Z",
     "shell.execute_reply": "2025-01-19T20:03:49.108592Z",
     "shell.execute_reply.started": "2025-01-19T20:03:29.027921Z"
    },
    "id": "ASJlTuYmxnsO",
    "outputId": "9ed19504-7bac-4222-c888-020177e711c0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40190a79c1064ecfa17ea7cbccd82620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac34cdc0d4504f7ca5d40d72b4fbdf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/317 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f6b6b8d1be46cfb1db3976433be91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5844f759a6d04f72a12c05900ab738bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973ded4610ed42b2a60c0283e397b9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd7fb60c4ef48a6acc729c1a3ead466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efb9f578ae547fe907566bd7523647a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917babb7345447459fbf2191f2b8669d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"clarin-pl/poquad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IArBUss6j5L"
   },
   "source": [
    "Sprawdźmy co znajduje się w zbiorze danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:12:53.549205Z",
     "iopub.status.busy": "2025-01-19T20:12:53.549205Z",
     "iopub.status.idle": "2025-01-19T20:12:53.554222Z",
     "shell.execute_reply": "2025-01-19T20:12:53.554222Z",
     "shell.execute_reply.started": "2025-01-19T20:12:53.549205Z"
    },
    "id": "MpE1sTIuwKr0",
    "outputId": "7e655d5f-cfa3-4171-c280-5293538c314d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 46187\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 5764\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qu_APsiB6mLo"
   },
   "source": [
    "Zbiór danych jest podzielony na dwie części: treningową i walidacyjną. Rozmiar części treningowej to ponad 46 tysięcy pytań i odpowiedzi, natomiast części walidacyjnej to ponad 5 tysięcy pytań i odpowiedzi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxdjcmsD6yc6"
   },
   "source": [
    "Dane zbioru przechowywane są w plikach `poquad_train.json` oraz `poquad_dev.json`. Dostarczenie podziału na te grupy danych jest bardzo częstą praktyką w przypadku publicznych, dużych zbiorów danych, gdyż umożliwia porównywanie różnych modeli, korzystając z dokładnie takiego samego zestawu danych. Prawdopodobnie istnieje również zbiór `poquad_test.json`, który jednak nie jest udostępniany publicznie. Tak jest w przypadku SQuADu - twórcy zbioru automatycznie ewaluują dostarczane modele, ale nie udstoępniaja zbioru testowego. Dzięki temu trudniej jest nadmiernie dopasować model do danych testowych.\n",
    "\n",
    "Struktura każdej z dostępnych części jest taka sama. Zgodnie z powyższą informacją zawiera ona następujące elementy:\n",
    "* `id` - identyfikator pary: pytanie - odpowiedź,\n",
    "* `title` - tytuł artykułu z Wikipedii, na podstawie którego utworzono parę,\n",
    "* `context` - fragment treści artykułu z Wikipedii, zawierający odpowiedź na pytanie,\n",
    "* `question` - pytanie,\n",
    "* `answers` - odpowiedzi.\n",
    "\n",
    "Możemy wyświetlić kilka począkotwych wpisów części treningowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:13:00.981721Z",
     "iopub.status.busy": "2025-01-19T20:13:00.981721Z",
     "iopub.status.idle": "2025-01-19T20:13:01.070018Z",
     "shell.execute_reply": "2025-01-19T20:13:01.070018Z",
     "shell.execute_reply.started": "2025-01-19T20:13:00.981721Z"
    },
    "id": "i3ZLmxlzx4wd",
    "outputId": "103735b5-7532-44fa-f5f9-d113edb42ded",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Co było powodem powrócenia konceptu porozumieniu monachijskiego?',\n",
       " 'Pomiędzy jakimi stronami odbyło się zgromadzenie w sierpniu 1942 roku?',\n",
       " 'O co ubiegali się polscy przedstawiciele podczas spotkania z sierpnia 1942 roku?',\n",
       " \"Który z dyplomatów sprzeciwił się konceptowi konfederacji w listopadzie '42?\",\n",
       " 'Kiedy oficjalnie doszło do zawarcia porozumienia?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['question'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:13:01.267217Z",
     "iopub.status.busy": "2025-01-19T20:13:01.267217Z",
     "iopub.status.idle": "2025-01-19T20:13:02.199342Z",
     "shell.execute_reply": "2025-01-19T20:13:02.199342Z",
     "shell.execute_reply.started": "2025-01-19T20:13:01.267217Z"
    },
    "id": "-YewsI8Dymaq",
    "outputId": "2b6e8041-c797-4f40-eb0b-c3b3d250ff64",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ['wymianą listów Ripka – Stroński'], 'answer_start': [117]},\n",
       " {'text': ['E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego'],\n",
       "  'answer_start': [197]},\n",
       " {'text': ['podpisanie układu konfederacyjnego'], 'answer_start': [315]},\n",
       " {'text': ['E. Beneš'], 'answer_start': [558]},\n",
       " {'text': ['20 listopada 1942'], 'answer_start': [691]}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['answers'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rlhCQp_3kEJ"
   },
   "source": [
    "Niestety, autorzy zbioru danych, pomimo tego, że dane te znajdują się w źródłowym zbiorze danych, nie udostępniają dwóch ważnych informacji: o tym, czy można odpowiedzieć na dane pytanie oraz jak brzmi generatywna odpowiedź na pytanie. Dlatego póki nie zostanie to naprawione, będziemy dalej pracowąć z oryginalnymi plikami zbioru danych, które dostępne są na stronie opisującej zbiór danych: https://huggingface.co/datasets/clarin-pl/poquad/tree/main\n",
    "\n",
    "Pobierz manualnie zbiory `poquad-dev.json` oraz `poquad-train.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:13:08.123727Z",
     "iopub.status.busy": "2025-01-19T20:13:08.123727Z",
     "iopub.status.idle": "2025-01-19T20:13:08.221942Z",
     "shell.execute_reply": "2025-01-19T20:13:08.221942Z",
     "shell.execute_reply.started": "2025-01-19T20:13:08.123727Z"
    },
    "id": "JoRrYJfO4Gs1",
    "outputId": "6d9725d4-ada9-48e1-98b5-dc4069700489",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/datasets/clarin-pl/poquad/raw/main/poquad-dev.json\n",
    "!wget https://huggingface.co/datasets/clarin-pl/poquad/resolve/main/poquad-train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPQoBTFn4S30"
   },
   "source": [
    "Dla bezpieczeństwa, jeśli korzystamy z Google drive, to przeniesiemy pliki do naszego dysku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtqQsRgB4O-W",
    "outputId": "7eb03fcc-d300-485e-aebd-8306ed26f58e"
   },
   "outputs": [],
   "source": [
    "!mkdir gdrive/MyDrive/poquad\n",
    "!mv poquad-dev.json gdrive/MyDrive/poquad\n",
    "!mv poquad-train.json gdrive/MyDrive/poquad\n",
    "\n",
    "!head -30 gdrive/MyDrive/poquad/poquad-dev.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjFnqM538V_9"
   },
   "source": [
    "Struktura pliku odpowiada strukturze danych w zbiorze SQuAD. Dane umieszczone są w kluczu `data` i podzielone na krotki odpowiadające pojedynczym artykułom Wikipedii. W ramach artykułu może być wybranych jeden lub więcej paragrafów, dla których w kluczu `qas` pojawiają się pytania (`question`), flaga `is_impossible`, wskazujace czy można odpowiedzieć na pytanie oraz odpowiedzi (o ile nie jest ustawiona flaga `is_impossible`). Odpowiedzi może być wiele i składają się one z treści odpowiedzi (`text`) traktowanej jako fragment kontekstu, a także naturalnej odpowiedzi na pytanie (`generative_answer`).\n",
    "\n",
    "Taki podział może wydawać się dziwny, ale zbiór SQuAD zawiera tylko odpowiedzi pierwszego rodzaju. Wynika to z faktu, że w języku angielskim fragment tekstu będzie często stanowił dobrą odpowiedź na pytanie (oczywiście z wyjątkiem pytań dla których odpowiedź to `tak` lub `nie`).\n",
    "\n",
    "Natomiast ten drugi typ odpowiedzi jest szczególnie przydatny dla języka polskiego, ponieważ często odpowiedź chcemy syntaktycznie dostosować do pytania, co jest niemożliwe, jeśli odpowiedź wskazywana jest jako fragment kontekstu.\n",
    "W sytuacji, w której odpowiedzi były określane w sposób automatyczny, są one oznaczone jako `plausible_answers`.\n",
    "\n",
    "Zaczniemy od wczytania danych i wyświetlenia podstawowych statystyk dotyczących ilości artykułów oraz przypisanych do nich pytań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:19:47.606207Z",
     "iopub.status.busy": "2025-01-19T20:19:47.606207Z",
     "iopub.status.idle": "2025-01-19T20:19:49.158445Z",
     "shell.execute_reply": "2025-01-19T20:19:49.158445Z",
     "shell.execute_reply.started": "2025-01-19T20:19:47.606207Z"
    },
    "id": "BDbf_9LKxuyJ",
    "outputId": "e15c36f6-d2b0-436c-83d3-15626c5f194c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data articles: 8553\n",
      "Dev data articles: 1402\n",
      "Train questions: 41577\n",
      "Dev questions: 6809\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"poquad-train.json\") as input:\n",
    "    train_data = json.loads(input.read())[\"data\"]\n",
    "\n",
    "print(f\"Train data articles: {len(train_data)}\")\n",
    "\n",
    "with open(\"poquad-dev.json\") as input:\n",
    "    dev_data = json.loads(input.read())[\"data\"]\n",
    "\n",
    "print(f\"Dev data articles: {len(dev_data)}\")\n",
    "\n",
    "print(f\"Train questions: {sum([len(e['paragraphs'][0]['qas']) for e in train_data])}\")\n",
    "print(f\"Dev questions: {sum([len(e['paragraphs'][0]['qas']) for e in dev_data])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrLTRuCz-4nv"
   },
   "source": [
    "Ponieważ w pierwszym problemie chcemy stwierdzić, czy na pytanie można udzielić odpowiedzi na podstawie kontekstu, połączymy wszystkie konteksty w jedną tablicę, aby móc losować z niej dane negatywne, gdyż liczba pytań nie posiadających odpowiedzi jest stosunkowo mała, co prowadziłoby utworzenia niezbalansowanego zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:19:52.979072Z",
     "iopub.status.busy": "2025-01-19T20:19:52.979072Z",
     "iopub.status.idle": "2025-01-19T20:19:52.988587Z",
     "shell.execute_reply": "2025-01-19T20:19:52.988587Z",
     "shell.execute_reply.started": "2025-01-19T20:19:52.979072Z"
    },
    "id": "c-1WgbVA1wsy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_contexts = [e[\"paragraphs\"][0][\"context\"] for e in train_data] + [\n",
    "    e[\"paragraphs\"][0][\"context\"] for e in dev_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Md-nxc7_jPy"
   },
   "source": [
    "W kolejnym kroku zamieniamy dane w formacie JSON na reprezentację zgodną z przyjętym założeniem.\n",
    "Chcemy by kontekst oraz pytanie występowały obok siebie i każdy z elementów był sygnalizowany wyrażeniem: `Pytanie:` i `Kontekst:`. Treść klasyfikowanego tekstu przyporządkowujemy do klucza `text`, natomiast klasę do klucza `label`, gdyż takie są oczekiwanie biblioteki Transformer.\n",
    "\n",
    "Pytania, które mają ustawiną flagę `is_impossible` na `True` trafiają wprost do przekształconego zbioru. Dla pytań, które posiadają odpowiedź, dodatkowo losowany jest jeden kontekst, który stanowi negatywny przykład. Weryfikujemy tylko, czy kontekst ten nie pokrywa się z kontekstem, który przypisany był do pytania. Nie przeprowadzamy bardziej zaawansowanych analiz, które pomogłyby wylkuczyć sytuację, w której inny kontekst również zawiera odpowiedź na pytanie, gdyż prawdopodobieństwo wylosowania takiego kontekstu jest bardzo małe.\n",
    "\n",
    "Na końcu wyświetlamy statystyki utworzonego zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:20:02.677712Z",
     "iopub.status.busy": "2025-01-19T20:20:02.676206Z",
     "iopub.status.idle": "2025-01-19T20:20:02.893511Z",
     "shell.execute_reply": "2025-01-19T20:20:02.893511Z",
     "shell.execute_reply.started": "2025-01-19T20:20:02.677712Z"
    },
    "id": "lbCkeE_f5Yg8",
    "outputId": "4015db0c-9826-4d88-f1cf-c9b9989f8c87",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count in train/dev: 75605/12372\n",
      "Positive count in train/dev: 34028/5563\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "tuples = [[], []]\n",
    "\n",
    "for idx, dataset in enumerate([train_data, dev_data]):\n",
    "    for data in dataset:\n",
    "        context = data[\"paragraphs\"][0][\"context\"]\n",
    "        for question_answers in data[\"paragraphs\"][0][\"qas\"]:\n",
    "            question = question_answers[\"question\"]\n",
    "            if question_answers[\"is_impossible\"]:\n",
    "                tuples[idx].append(\n",
    "                    {\n",
    "                        \"text\": f\"Pytanie: {question} Kontekst: {context}\",\n",
    "                        \"label\": 0,\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                tuples[idx].append(\n",
    "                    {\n",
    "                        \"text\": f\"Pytanie: {question} Kontekst: {context}\",\n",
    "                        \"label\": 1,\n",
    "                    }\n",
    "                )\n",
    "                while True:\n",
    "                    negative_context = random.choice(all_contexts)\n",
    "                    if negative_context != context:\n",
    "                        tuples[idx].append(\n",
    "                            {\n",
    "                                \"text\": f\"Pytanie: {question} Kontekst: {negative_context}\",\n",
    "                                \"label\": 0,\n",
    "                            }\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "train_tuples, dev_tuples = tuples\n",
    "print(f\"Total count in train/dev: {len(train_tuples)}/{len(dev_tuples)}\")\n",
    "print(\n",
    "    f\"Positive count in train/dev: {sum([e['label'] for e in train_tuples])}/{sum([e['label'] for e in dev_tuples])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2fQbatcAj5b"
   },
   "source": [
    "Widzimy, że uzyskane zbiory danych cechują się dość dobrym zbalansowaniem.\n",
    "\n",
    "Dobrą praktyką po wprowadzeniu zmian w zbiorze danych, jest wyświetlenie kilku przykładowych punktów danych, w celu wykrycia ewentualnych błędów, które powstały na etapie konwersji zbioru. Pozwala to uniknąć nieprzyjemnych niespodzianek, np. stworzenie identycznego zbioru danych testowych i treningowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:21:41.082729Z",
     "iopub.status.busy": "2025-01-19T20:21:41.082729Z",
     "iopub.status.idle": "2025-01-19T20:21:41.086431Z",
     "shell.execute_reply": "2025-01-19T20:21:41.086431Z",
     "shell.execute_reply.started": "2025-01-19T20:21:41.082729Z"
    },
    "id": "Lr-oeLgR9H75",
    "outputId": "e0e0f02b-3fcd-44f8-9521-c966e6b7a6c3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Pytanie: Co było powodem powrócenia konceptu porozumieniu monachijskiego? Kontekst: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942).', 'label': 1}]\n",
      "[{'text': 'Pytanie: Czym są pisma rabiniczne? Kontekst: Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik.', 'label': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(train_tuples[0:1])\n",
    "print(dev_tuples[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTTry7LfBXKb"
   },
   "source": [
    "Ponieważ mamy nowe zbiory danych, możemy opakować je w klasy ułatwiające manipulowanie nimi. Ma to szczególne znaczenie w kontekście szybkiej tokenizacji tych danych, czy późniejszego szybkiego wczytywania wcześniej utworzonych zbiorów danych.\n",
    "\n",
    "W tym celu wykorzystamy bibliotekę `datasets`. Jej kluczowymi klasami są `Dataset` reprezentujący jeden z podzbiorów zbioru danych (np. podzbiór testowy) oraz `DatasetDict`, który łączy wszystkie podzbiory w jeden obiekt, którym możemy manipulować w całości. (Gdyby autorzy udostępnili odpowiedni skrypt ze zbiorem, moglibyśmy wykorzystać tę bibliotekę bez dodatkowej pracy).\n",
    "\n",
    "Dodatkowo zapiszemy tak utworzony zbiór danych na dysku. Jeśli później chcielibyśmy wykorzystać stworzony zbiór danych, to możemy to zrobić za pomocą komendy `load_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:21:54.150080Z",
     "iopub.status.busy": "2025-01-19T20:21:54.150080Z",
     "iopub.status.idle": "2025-01-19T20:21:54.713729Z",
     "shell.execute_reply": "2025-01-19T20:21:54.713729Z",
     "shell.execute_reply.started": "2025-01-19T20:21:54.150080Z"
    },
    "id": "rtTsPgmiDdG8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93879e7d26764b9f8463073932d09fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/75605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3139ceb4072a44a292407bf408c06643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_list(train_tuples)\n",
    "dev_dataset = Dataset.from_list(dev_tuples)\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"dev\": dev_dataset})\n",
    "datasets.save_to_disk(\"question-context-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORcWOWjiCAhu"
   },
   "source": [
    "Dane tekstowe przed przekazaniem do modelu wymagają tokenizacji (co widzieliśmy już wcześniej). Efektywne wykonanie tokenizacji na całym zbiorze danych ułatwione jest przez obiekt `DatasetDict`. Definiujemy funkcję `tokenize_function`, która korzystając z załadowanego tokenizera, zamienia tekst na identyfikatory.\n",
    "\n",
    "W wywołaniu używamy opcji `padding` - uzupełniamy wszystkie teksty do długości najdłuższego tekstu. Dodatkowo, jeśli któryś tekst wykracza poza maksymalną długość obsługiwaną przez model, to jest on przycinany (`truncation=True`).\n",
    "\n",
    "Tokenizację aplikujemy do zbioru z wykorzystaniem przetwarzania batchowego (`batched=True`), które pozwala na szybsze stokenizowanie dużego zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:36:49.932286Z",
     "iopub.status.busy": "2025-01-19T20:36:49.932286Z",
     "iopub.status.idle": "2025-01-19T20:37:24.500672Z",
     "shell.execute_reply": "2025-01-19T20:37:24.500672Z",
     "shell.execute_reply.started": "2025-01-19T20:36:49.932286Z"
    },
    "id": "WLJSYvpFFlfO",
    "outputId": "ea1d2507-427d-44ec-bd0d-eb73f0aedb60",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415e4e6e838340fe9299c6669e9db946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02a1b2d2f834c9ba3910268e05cbbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 75605\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "pl_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return pl_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5FJ54OLS0hK"
   },
   "source": [
    "Stokenizowane dane zawierają dodatkowe pola: `input_ids`, `token_type_ids` oraz `attention_mask`. Dla nas najważniejsze jest pole `input_ids`, które zawiera identyfikatory tokenów. Pozostałe dwa pola są ustawione na identyczne wartości (wszystkie tokeny mają ten sam typ, maska atencji zawiera wszystkie niezerowe tokeny), więc nie są one dla nas zbyt interesujące. Zobaczmy pola `text`, `input_ids` oraz `attention_mask` dla pierwszego przykładu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:41:45.597006Z",
     "iopub.status.busy": "2025-01-19T20:41:45.597006Z",
     "iopub.status.idle": "2025-01-19T20:41:46.210298Z",
     "shell.execute_reply": "2025-01-19T20:41:46.210298Z",
     "shell.execute_reply.started": "2025-01-19T20:41:45.597006Z"
    },
    "id": "mgCExFTHSEYq",
    "outputId": "d612f2ce-b33f-4b9a-a31b-a8f51d285e26",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Co było powodem powrócenia konceptu porozumieniu monachijskiego? Kontekst: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942).\n",
      "[0, 14142, 1335, 3407, 2404, 14736, 6491, 4081, 6743, 2213, 19824, 25437, 3096, 13875, 1550, 2922, 8413, 1335, 46771, 2152, 17914, 10278, 2022, 11314, 37410, 1008, 4983, 19240, 1899, 38382, 14919, 9091, 25437, 3096, 18290, 1947, 2249, 89, 12539, 2742, 2135, 2022, 45310, 8404, 6242, 8221, 1680, 7701, 2547, 1899, 5016, 2571, 4983, 19240, 5073, 2041, 4261, 1039, 1899, 13287, 254, 1011, 1009, 1071, 1899, 2306, 7634, 40838, 1046, 4192, 1011, 59, 1032, 1899, 25496, 1009, 1039, 1899, 2710, 11553, 1046, 3885, 3441, 1899, 24175, 11467, 2057, 35267, 26991, 10374, 2152, 11098, 1990, 4206, 1899, 1049, 13360, 11794, 1947, 11171, 1899, 2902, 4464, 1947, 11287, 7677, 11610, 2158, 1998, 6428, 1071, 1899, 2306, 7634, 40838, 4555, 17695, 1007, 24584, 2152, 17914, 5351, 8373, 1899, 24649, 2052, 2014, 21425, 3056, 4555, 16248, 1947, 4269, 2267, 1019, 11738, 19240, 1039, 1899, 13287, 1107, 33851, 4561, 28060, 2152, 17914, 1899, 1049, 11721, 34366, 36004, 10374, 20003, 5311, 1046, 11695, 1998, 2440, 2460, 1341, 19046, 14608, 2063, 2440, 5252, 19240, 1940, 1899, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_datasets[\"train\"][0]\n",
    "print(example[\"text\"])\n",
    "print(example[\"input_ids\"])\n",
    "print(example[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnG0EEHi782A"
   },
   "source": [
    "Możem też sprawdzić, jak został stokenizowany pierwszy przykład:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:41:51.191206Z",
     "iopub.status.busy": "2025-01-19T20:41:51.191206Z",
     "iopub.status.idle": "2025-01-19T20:41:51.199788Z",
     "shell.execute_reply": "2025-01-19T20:41:51.199788Z",
     "shell.execute_reply.started": "2025-01-19T20:41:51.191206Z"
    },
    "id": "NsfJDuhN8Acj",
    "outputId": "11ecd719-6553-4d0b-c4a0-71d7eb29f65d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>|Pytanie</w>|:</w>|Co</w>|było</w>|powodem</w>|powró|cenia</w>|koncep|tu</w>|porozumieniu</w>|mona|chi|jskiego</w>|?</w>|Kon|tekst</w>|:</w>|Projekty</w>|kon|federacji</w>|zaczęły</w>|się</w>|zała|mywać</w>|5</w>|sierpnia</w>|1942</w>|.</w>|Ponownie</w>|wróciła</w>|kwestia</w>|mona|chi|jska</w>|,</w>|co</w>|u|akty|wni|ło</w>|się</w>|wymianą</w>|listów</w>|Ri|pka</w>|–</w>|Stro|ński</w>|.</w>|Natomiast</w>|17</w>|sierpnia</w>|1942</w>|doszło</w>|do</w>|spotkania</w>|E</w>|.</w>|Bene|š|a</w>|i</w>|J</w>|.</w>|Ma|sar|yka</w>|z</w>|jednej</w>|a</w>|W|ł</w>|.</w>|Sikorskiego</w>|i</w>|E</w>|.</w>|Ra|czyńskiego</w>|z</w>|drugiej</w>|strony</w>|.</w>|Polscy</w>|dyploma|ci</w>|zaproponowali</w>|podpisanie</w>|układu</w>|kon|fede|ra|cyjnego</w>|.</w>|W</w>|następnym</w>|miesiącu</w>|,</w>|tj</w>|.</w>|24</w>|września</w>|,</w>|strona</w>|polska</w>|przesł|ała</w>|na</w>|ręce</w>|J</w>|.</w>|Ma|sar|yka</w>|projekt</w>|deklaracji</w>|o</w>|przyszłej</w>|kon|federacji</w>|obu</w>|państw</w>|.</w>|Strona</w>|cze|ch|osłowa|cka</w>|projekt</w>|przyjęła</w>|,</w>|lecz</w>|już</w>|w</w>|listopadzie</w>|1942</w>|E</w>|.</w>|Bene|š</w>|podwa|żył</w>|ideę</w>|kon|federacji</w>|.</w>|W</w>|zamian</w>|zaproponowano</w>|zawarcie</w>|układu</w>|sojusz|niczego</w>|z</w>|Polską</w>|na</w>|20</w>|lat</w>|(</w>|formalnie</w>|nastąpiło</w>|to</w>|20</w>|listopada</w>|1942</w>|)</w>|.</w>|</s>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>|<pad>\n"
     ]
    }
   ],
   "source": [
    "print(\"|\".join(pl_tokenizer.convert_ids_to_tokens(list(example[\"input_ids\"]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DL-RiReUT6e"
   },
   "source": [
    "Widzimy, że wyrazy podzielone są sensownie, a na końcu tekstu pojawiają się tokeny wypełnienia (PAD). Oznacza to, że zdanie zostało poprawnie skonwertowane.\n",
    "\n",
    "Możemy sprawdzić, że liczba tokenów w polu `inut_ids`, które są różne od tokenu wypełnienia (`[PAD] = 1`) oraz maska atencji, mają tę samą długość:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:41:53.550206Z",
     "iopub.status.busy": "2025-01-19T20:41:53.550206Z",
     "iopub.status.idle": "2025-01-19T20:41:53.555234Z",
     "shell.execute_reply": "2025-01-19T20:41:53.554719Z",
     "shell.execute_reply.started": "2025-01-19T20:41:53.550206Z"
    },
    "id": "QeSZdD09T7TH",
    "outputId": "3c618ef0-89dc-4c21-fdec-ccb47fd80c25",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "print(len([e for e in example[\"input_ids\"] if e != 1]))\n",
    "print(len([e for e in example[\"attention_mask\"] if e == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKm4X7jzUjW7"
   },
   "source": [
    "Mając pewność, że przygotowane przez nas dane są prawidłowe, możemy przystąpić do procesu uczenia modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmVeK74JVPKz"
   },
   "source": [
    "## Trening z użyciem transformersów\n",
    "\n",
    "Biblioteka Transformes pozwala na załadowanie tego samego modelu dostosowanego do różnych zadań. Wcześniej używaliśmy modelu HerBERT do predykcji brakującego wyrazu. Teraz załadujemy ten sam model, ale z inną \"głową\". Zostanie użyta warstwa, która pozwala na klasyfikację całego tekstu do jednej z n-klas. Wystarczy podmienić klasę, za pomocą której ładujemy model na `AutoModelForSequenceClassification`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:41:56.395207Z",
     "iopub.status.busy": "2025-01-19T20:41:56.395207Z",
     "iopub.status.idle": "2025-01-19T20:41:58.875020Z",
     "shell.execute_reply": "2025-01-19T20:41:58.875020Z",
     "shell.execute_reply.started": "2025-01-19T20:41:56.395207Z"
    },
    "id": "cVs4tK1WHUT8",
    "outputId": "6a8bfb27-1f4a-49b5-fc49-35bcea855404",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"allegro/herbert-base-cased\", num_labels=2\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axdrBfSuE5YO"
   },
   "source": [
    "Komunikat diagnostyczny, który pojawia się przy ładowaniu modelu jest zgodny z naszymi oczekiwaniami. Model HerBERT był trenowany do predykcji tokenów, a nie klasyfikacji tekstu. Dlatego też ostatnia warstwa (`classifier.weight` oraz `classifier.bias`) jest inicjowana losowo. Wagi zostaną ustalone w trakcie procesu fine-tuningu modelu.\n",
    "\n",
    "Jeśli porównamy wersje modeli załadowane za pomocą różnych klas, to zauważymy, że różnią się one tylko na samym końcu. Jest to zgodne z założeniami procesu pre-treningu i fine-tuningu. W pierwszy etapie model uczy się zależności w języku, korzystając z zadania maskowanego modelowania języka (Masked Language Modeling). W drugim etapie model dostosowywane jest do konkretnego zadania, np. klasyfikacji binarnej tekstu.\n",
    "\n",
    "Korzystanie z biblioteki Transformers uwalnia nas od manualnego definiowania pętli uczącej, czy wywoływania algorytmu wstecznej propagacji błędu. Trening realizowany jest z wykorzystaniem klasy `Trainer`  (i jej specjlizacji). Argumenty treningu określane są natomiast w klasie `TrainingArguments`.  Klasy te są [bardzo dobrze udokumentowane](https://huggingface.co/docs/transformers/main_classes/trainer#trainer), więc nie będziemy omawiać wszystkich możliwych opcji.\n",
    "\n",
    "Najważniejsze opcje są następujące:\n",
    "* `output_dir` - katalog do którego zapisujemy wyniki,\n",
    "* `do_train` - wymagamy aby przeprowadzony był trening,\n",
    "* `do_eval` - wymagamy aby przeprowadzona była ewaluacja modelu,\n",
    "* `evaluation_strategy` - określenie momentu, w którym realizowana jest ewaluacja,\n",
    "* `evaluation_steps` - określenie co ile kroków (krok = przetworzenie 1 batcha) ma być realizowana ewaluacja,\n",
    "* `per_device_train/evaluation_batch_size` - rozmiar batcha w trakcie treningu/ewaluacji,\n",
    "* `learning_rate` - szybkość uczenia,\n",
    "* `num_train_epochs` - liczba epok uczenia,\n",
    "* `logging`... - parametry logowania postępów uczenia,\n",
    "* `save_strategy` - jak często należy zapisywać wytrenowany model,\n",
    "* `fp16/bf16` - użycie arytmetyki o zmniejszonej dokładności, przyspieszającej proces uczenia. **UWAGA**: użycie niekompatybilnej arytmetyki skutkuje niemożnością nauczenia modelu, co jednak nie daje żadnych innych błędów lub komunikatów ostrzegawczych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:42:20.510206Z",
     "iopub.status.busy": "2025-01-19T20:42:20.510206Z",
     "iopub.status.idle": "2025-01-19T20:42:20.649604Z",
     "shell.execute_reply": "2025-01-19T20:42:20.649604Z",
     "shell.execute_reply.started": "2025-01-19T20:42:20.510206Z"
    },
    "id": "Iub6XtjPH7O6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-05,\n",
    "    num_train_epochs=1,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlShURnsVAXC"
   },
   "source": [
    "W trakcie treningu będziemy chcieli zobaczyć, czy model poprawnie radzi sobie z postawionym mu problemem. Najlepszym sposobem na podglądanie tego procesu jest obserwowanie wykresów. Model może raportować szereg metryk, ale najważniejsze dla nas będą następujące wartości:\n",
    "* wartość funkcji straty na danych treningowych - jeślie nie spada w trakcie uczenia, znaczy to, że nasz model nie jest poprawnie skonstruowany lub dane uczące są niepoprawne,\n",
    "* wartość jednej lub wielu metryk uzyskiwanych na zbiorze walidacyjnym - możemy śledzić wartość funkcji straty na zbiorze ewaluacyjnym, ale warto również wyświetlać metryki, które da się łatwiej zinterpretować; dla klasyfikacji zbalansowanego zbioru danych może to być dokładność (`accuracy`).\n",
    "\n",
    "Biblioteka Transformers pozwala w zasadzie na wykorzystanie dowolnej metryki, ale szczególnie dobrze współpracuje z metrykami zdefiniowanymi w bibliotece `evaluate` (również autorstwa Huggingface).\n",
    "\n",
    "Wykorzystanie metryki wymaga od nas zdefiniowania metody, która akceptuje batch danych, który zawieraja predykcje (wektory zwrócone na wyjściu modelu) oraz referencyjne wartości - wartości przechowywane w kluczu `label`. Przed obliczeniem metryki konieczne jest \"odcyfrowanie\" zwróconych wartości. W przypadku klasyfikacji oznacza to po prostu wybranie najbardziej prawodopodobnej klasy i porównanie jej z klasą referencyjną.\n",
    "\n",
    "Użycie konkretnej metryki realizowane jest za pomocą wywołania `metric.compute`, która akceptuje predykcje (`predictions`) oraz wartości referencyjne (`references`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:42:31.609206Z",
     "iopub.status.busy": "2025-01-19T20:42:31.608206Z",
     "iopub.status.idle": "2025-01-19T20:42:37.866249Z",
     "shell.execute_reply": "2025-01-19T20:42:37.866249Z",
     "shell.execute_reply.started": "2025-01-19T20:42:31.609206Z"
    },
    "id": "S861cZksGrWM",
    "outputId": "c2027b56-3d3e-44b2-8172-e5be306392e5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8b00a643ad4661b5a1bc6d6482afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1qk791L6_I7"
   },
   "source": [
    "Ostatnim krokiem w procesie treningu jest stworzenie obiektu klasy `Trainer`. Akceptuje ona m.in. model, który wykorzystywany jest w treningu, przygotowane argumenty treningu, zbiory do treningu, ewaluacji, czy testowania oraz wcześniej określoną metodę do obliczania metryki na danych ewaluacyjnych.\n",
    "\n",
    "W przetwarzaniu jezyka naturalnego dominującym podejściem jest obecnie rozdzielenie procesu treningu na dwa etapy: pre-treining oraz fine-tuning. W pierwszym etapie model trenowany jest w reżimie self-supervised learning (SSL). Wybierane jest zadanie związane najczęściej z modelowaniem języka - może to być kauzalne lub maskowane modelowanie języka.\n",
    "\n",
    "W *kauzalnym modelowaniu języka* model językowy, na podstawie poprzedzających wyrazów określa prawdopodobieństwo wystąpienia kolejnego wyrazu. W *maskowanym modelowaniu języka* model językowy odgaduje w tekście część wyrazów, która została z niego usunięta.\n",
    "\n",
    "W obu przypadkach dane, na których trenowany jest model nie wymagają ręcznego oznakowania (tagowaina). Wystarczy jedynie posiadać duży korpus danych językowych, aby wytrenować model, który dobrze radzi sobie z jednym z tych zadań. Model tego rodzaju był pokazany na początku laboratorium.\n",
    "\n",
    "W drugim etapie - fine-tuningu (dostrajaniu modelu) - następuje modyfikacja parametrów modelu, w celu rozwiązania konkretnego zadania. W naszym przypadku pierwszym zadaniem tego rodzaju jest klasyfikacja. Dostroimy zatem model `herbert-base-cased` do zadania klasyfikacji par: pytanie - kontekst.\n",
    "\n",
    "Wykorzystamy wcześniej utworzone zbiory danych i dodatkowo zmienimy kolejność danych, tak aby uniknąć potencjalnego problemu z korelacją danych w ramach batcha. Wykorzystujemy do tego wywołanie `shuffle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:45:07.562001Z",
     "iopub.status.busy": "2025-01-19T20:45:07.562001Z",
     "iopub.status.idle": "2025-01-19T20:45:08.139964Z",
     "shell.execute_reply": "2025-01-19T20:45:08.139964Z",
     "shell.execute_reply.started": "2025-01-19T20:45:07.562001Z"
    },
    "id": "zSM6Qmv_WUgz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:439: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42),\n",
    "    eval_dataset=tokenized_datasets[\"dev\"].shuffle(seed=42),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx8WSdqx9Hv5"
   },
   "source": [
    "Zanim uruchomimy trening, załadujemy jeszcze moduł TensorBoard. Nie jest to krok niezbędy. TensorBoard to biblioteka, która pozwala na wyświetlanie w trakcie procesu trening wartości, które wskazują nam, czy model trenuje się poprawnie. W naszym przypadku będzie to `loss` na danych treningowych, `loss` na danych ewaluacyjnych oraz wartość metryki `accuracy`, którą zdefiniowaliśmy wcześniej. Wywołanie tej komórki na początku nie da żadnego efektu, ale można ją odświeżać, za pomocą ikony w menu TensorBoard (ewentualnie włączyć automatyczne odświeżanie). Wtedy w miarę upływu treningu będziemy mieli podgląd, na przebieg procesu oraz osiągane wartości interesujących nas parametrów.\n",
    "\n",
    "Warto zauważyć, że istenieje szereg innych narzędzi do monitorowania eksperymentów z treningiem sieci. Wśród nich dużą popularnością cieszą się [WanDB](https://wandb.ai/site) oraz [Neptune.AI](https://neptune.ai/). Ich zaletą jest m.in. to, że możemy łatwo archiwizować przeprowadzone eksperymenty, porównywać je ze sobą, analizować wpływ hiperparametrów na uzyskane wyniki, itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:46:06.597715Z",
     "iopub.status.busy": "2025-01-19T20:46:06.596712Z",
     "iopub.status.idle": "2025-01-19T20:46:07.018790Z",
     "shell.execute_reply": "2025-01-19T20:46:07.018790Z",
     "shell.execute_reply.started": "2025-01-19T20:46:06.597715Z"
    },
    "id": "Qg3S3CanFoBE",
    "outputId": "121b8e50-27e7-41e5-cc6c-391bd254d240",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--logdir gdrive/MyDrive/poquad/output/runs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mextension_manager\u001b[38;5;241m.\u001b[39mload_extension(module_str)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_extension(module_str)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\IPython\\core\\extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m---> 91\u001b[0m         mod \u001b[38;5;241m=\u001b[39m import_module(module_str)\n\u001b[0;32m     92\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir gdrive/MyDrive/poquad/output/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5d5E2OO-P5C"
   },
   "source": [
    "Uruchomienie procesu treningu jest już bardzo proste, po tym jak przygotowaliśmy wszystkie niezbędne szczegóły. Wystarczy wywołać metodę `trainer.train()`. Warto mieć na uwadze, że proces ten będzie jednak długotrwały - jedna epoka treningu na przygotowanych danych będzie trwała ponad 1 godzinę. Na szczęście, dzięki ustawieniu ewaluacji co 300 kroków, będziemy mogli obserwować jak model radzie sobie z postawionym przed nim problemem na danych ewaluacyjnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T20:46:20.561714Z",
     "iopub.status.busy": "2025-01-19T20:46:20.561714Z",
     "iopub.status.idle": "2025-01-19T21:57:13.660225Z",
     "shell.execute_reply": "2025-01-19T21:57:13.657209Z",
     "shell.execute_reply.started": "2025-01-19T20:46:20.561714Z"
    },
    "id": "sULHvH_bMBmW",
    "outputId": "02de07d4-d959-4f97-ce3d-f54a4279c078",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4726' max='4726' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4726/4726 1:10:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.293112</td>\n",
       "      <td>0.888377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.336243</td>\n",
       "      <td>0.883285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.312724</td>\n",
       "      <td>0.883851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.295400</td>\n",
       "      <td>0.888943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.280198</td>\n",
       "      <td>0.889994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.291611</td>\n",
       "      <td>0.887407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.889751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.267405</td>\n",
       "      <td>0.893954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>0.258566</td>\n",
       "      <td>0.887165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.260537</td>\n",
       "      <td>0.899127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.251213</td>\n",
       "      <td>0.898642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.251193</td>\n",
       "      <td>0.900097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.256565</td>\n",
       "      <td>0.901309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.257334</td>\n",
       "      <td>0.901471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.251102</td>\n",
       "      <td>0.903492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4726, training_loss=0.2905385402416305, metrics={'train_runtime': 4252.8186, 'train_samples_per_second': 17.778, 'train_steps_per_second': 1.111, 'total_flos': 1.98925113404928e+16, 'train_loss': 0.2905385402416305, 'epoch': 1.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kmxKtZp_VP6"
   },
   "source": [
    "## Zadanie 3 (1 punkt)\n",
    "\n",
    "Wybierz losową stronę z Wikipedii i skopiuj fragment tekstu do Notebook. Zadaj 3 pytania, na które można udzielić odpowiedź na podstawie tego fragmentu tekstu oraz 3 pytania, na które nie można udzielić odpowiedzi. Oceń jakość predykcji udzielanych przez model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:45:54.130718Z",
     "iopub.status.busy": "2025-01-19T22:45:54.130718Z",
     "iopub.status.idle": "2025-01-19T22:45:56.016330Z",
     "shell.execute_reply": "2025-01-19T22:45:56.016330Z",
     "shell.execute_reply.started": "2025-01-19T22:45:54.130718Z"
    },
    "id": "Ou-a-tVoU9wG",
    "outputId": "32f70a73-848b-4e9c-80c1-d9db4a99dd07",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Bardziej trwałe sa karbokationy o wyższej czy niższej rzędowości? Kontekst: Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\n",
      "Odpowiedź modelu: Jest odpowiedz w tekście\n",
      "\n",
      "Pytanie: Od czego zależy reaktywność karbokationa? Kontekst: Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\n",
      "Odpowiedź modelu: Jest odpowiedz w tekście\n",
      "\n",
      "Pytanie: Czy obecność pierściennia aromatycznego działa stabiliząco bna karbokation? Kontekst: Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\n",
      "Odpowiedź modelu: Jest odpowiedz w tekście\n",
      "\n",
      "Pytanie: Czy pomidory to warzywa, a może owoc? Kontekst: Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\n",
      "Odpowiedź modelu: Jest odpowiedz w tekście\n",
      "\n",
      "Pytanie: Czy P=NP? Kontekst: Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\n",
      "Odpowiedź modelu: Nie ma odpowiedzi w tekście\n",
      "\n",
      "Pytanie: W któym roku otwarto wydział Informatyki AGH? Kontekst: Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\n",
      "Odpowiedź modelu: Nie ma odpowiedzi w tekście\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"Karbokation – kation, w którym elektryczny ładunek dodatni jest zlokalizowany na jednym lub kilku atomach węgla.Szczególnie nietrwałe i reaktywne są karbokationy alkilowe. Ich trwałość zależna jest jednak silnie od ich rzędowości, tzn. od tego, czy ładunek dodatni znajduje się na atomie węgla\"\n",
    "\n",
    "Q1=\"Bardziej trwałe sa karbokationy o wyższej czy niższej rzędowości?\"\n",
    "Q2=\"Od czego zależy reaktywność karbokationa?\"\n",
    "Q3=\"Czy obecność pierściennia aromatycznego działa stabiliząco bna karbokation?\"\n",
    "\n",
    "Q4=\"Czy pomidory to warzywa, a może owoc?\"\n",
    "Q5=\"Czy P=NP?\"\n",
    "Q6=\"W któym roku otwarto wydział Informatyki AGH?\"\n",
    "questions=[Q1,Q2,Q3,Q4,Q5,Q6]\n",
    "model.to(\"cpu\")\n",
    "def ask_model(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return model.config.id2label[predicted_class_id]\n",
    "\n",
    "label_map = {\n",
    "    'LABEL_0': 'Nie ma odpowiedzi w tekście',\n",
    "    'LABEL_1': 'Jest odpowiedz w tekście',\n",
    "}\n",
    "for question in questions:\n",
    "    \n",
    "    in_m = f\"Pytanie: {question} Kontekst: {context}\"\n",
    "    answer = ask_model(in_m)\n",
    "    print(f\"{in_m}\\nOdpowiedź modelu: {label_map[answer]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KcwGtp1xlDn"
   },
   "source": [
    "Stwierdził, że Artykuł o karbokationach z wikipedii odpowiada na pytanie o nature pomidora, więc dochodzę do wniosku, że coś poszło nie tak, natomiast poprawnie zakwalifikował resztę par (pytanie kontekst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJXK8qWCtoY-"
   },
   "source": [
    "# Odpowiadanie na pytania\n",
    "\n",
    "Drugim problemem, którym zajmie się w tym laboratorium jest odpowiadanie na pytania. Zmierzymy się z wariantem tego problemu, w którym model sam formułuje odpowiedź, na podstawie pytania i kontekstu, w których znajduje się odpowiedź na pytanie (w przeciwieństwie do wariantu, w którym model wskazuje lokalizację odpowiedzi na pytanie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL3VibwXYdu2"
   },
   "source": [
    "\n",
    "## Zadanie 4 (1 punkt)\n",
    "\n",
    "Rozpocznij od przygotowania danych. Wybierzem tylko te pytania, które posiadają odpowiedź (`is_impossible=False`). Uwzględnij zarówno pytania *pewne* (pole `answers`) jak i *prawdopodobne* (pole `plausible_answers`). Wynikowy zbiór danych powinien mieć identyczną strukturę, jak w przypadku zadania z klasyfikacją, ale etykiety zamiast wartości 0 i 1, powinny zawierać odpowiedź na pytanie, a sama nazwa etykiety powinna być zmieniona z `label` na `labels`, w celu odzwierciedlenia faktu, że teraz zwracane jest wiele etykiet.\n",
    "\n",
    "Wyświetl liczbę danych (par: pytanie - odpowiedź) w zbiorze treningowym i zbiorze ewaluacyjnym.\n",
    "\n",
    "Opakuj również zbiory w klasy z biblioteki `datasets` i zapisz je na dysku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:27:34.058323Z",
     "iopub.status.busy": "2025-01-19T23:27:34.057320Z",
     "iopub.status.idle": "2025-01-19T23:27:35.165944Z",
     "shell.execute_reply": "2025-01-19T23:27:35.165944Z",
     "shell.execute_reply.started": "2025-01-19T23:27:34.058323Z"
    },
    "id": "auGRaK7x1vf9",
    "outputId": "5a03bb5c-c87b-40dd-d7b1-a93cc3a7b7b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count in train/dev: 34028/5563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e77e5ba0a14384afe1262e55b36ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/34028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcb15779f37479fb2110e61a4f60c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "with open(\"poquad-train.json\") as input:\n",
    "    train_data = json.loads(input.read())[\"data\"]\n",
    "\n",
    "with open(\"poquad-dev.json\") as input:\n",
    "    dev_data = json.loads(input.read())[\"data\"]\n",
    "\n",
    "tuples = [[], []]\n",
    "\n",
    "for idx, dataset in enumerate([train_data, dev_data]):\n",
    "    for data in dataset:\n",
    "        context = data[\"paragraphs\"][0][\"context\"]\n",
    "        for question_answers in data[\"paragraphs\"][0][\"qas\"]:\n",
    "            question = question_answers[\"question\"]\n",
    "            \n",
    "            if not question_answers[\"is_impossible\"]:\n",
    "\n",
    "                answers = question_answers.get(\"answers\", [])\n",
    "                plausible_answers = question_answers.get(\"plausible_answers\", [])\n",
    "                all_answers = answers + plausible_answers\n",
    "                \n",
    "                \n",
    "                tuples[idx].append(\n",
    "                        {\n",
    "                            \"text\": f\"Pytanie: {question} Kontekst: {context}\",\n",
    "                            \"labels\": list(map(lambda x: x[\"text\"], all_answers))[0]\n",
    "                        }\n",
    "                )\n",
    "\n",
    "train_tuples, dev_tuples = tuples\n",
    "\n",
    "print(f\"Total count in train/dev: {len(train_tuples)}/{len(dev_tuples)}\")\n",
    "\n",
    "train_dataset = Dataset.from_list(train_tuples)\n",
    "dev_dataset = Dataset.from_list(dev_tuples)\n",
    "\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"dev\": dev_dataset})\n",
    "\n",
    "# Save the datasets to disk\n",
    "datasets.save_to_disk(\"question-context-ans\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsZe71D5FMhw"
   },
   "source": [
    "Zanim przejdziemy do dalszej części, sprawdźmy, czy dane zostały poprawnie utworzone. Zweryfikujmy przede wszystkim, czy klucze `text` oraz `label` zawieraja odpowiednie wartości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:27:42.148784Z",
     "iopub.status.busy": "2025-01-19T23:27:42.147780Z",
     "iopub.status.idle": "2025-01-19T23:27:42.153771Z",
     "shell.execute_reply": "2025-01-19T23:27:42.153250Z",
     "shell.execute_reply.started": "2025-01-19T23:27:42.148784Z"
    },
    "id": "ZN8Q0h7PF_aw",
    "outputId": "42d1c7f9-5f9e-49f9-a96c-bf9ee738a660",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Co było powodem powrócenia konceptu porozumieniu monachijskiego? Kontekst: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942).\n",
      "wymianą listów Ripka – Stroński\n",
      "Pytanie: Czym są pisma rabiniczne? Kontekst: Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik.\n",
      "kompilację poglądów różnych rabinów na określony temat\n"
     ]
    }
   ],
   "source": [
    "print(datasets[\"train\"][0][\"text\"])\n",
    "print(datasets[\"train\"][0][\"labels\"])\n",
    "print(datasets[\"dev\"][0][\"text\"])\n",
    "print(datasets[\"dev\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLghVU7EEaHb"
   },
   "source": [
    "Tokenizacja danych dla problemu odpowiadania na pytania jest nieco bardziej problematyczna. W pierwszej kolejności trzeba wziąć pod uwagę, że dane wynikowe (etykiety), też muszą podlegać tokenizacji. Realizowane jest to poprzez wywołanie tokenizera, z opcją `text_target` ustawioną na łańcuch, który ma być stokenizowany.\n",
    "\n",
    "Ponadto wcześniej nie przejmowaliśmy się za bardzo tym, czy wykorzystywany model obsługuje teksty o założonej długości. Teraz jednak ma to duże znaczenie. Jeśli użyjemy modelu, który nie jest w stanie wygenerować odpowiedzi o oczekiwanej długości, to nie możemy oczekiwać, że model ten będzie dawał dobre rezultaty dla danych w zbiorze treningowym i testowym.\n",
    "\n",
    "W pierwszej kolejności dokonamy więc tokenizacji bez ograniczeń co do długości tekstu. Ponadto, stokenizowane odpowiedzi przypiszemy do klucza `label`. Do tokenizacji użyjemy tokenizera stowarzyszonego z modelem  `allegro/plt5-base`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T10:30:09.564553Z",
     "start_time": "2022-12-22T10:30:09.155839Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-19T23:27:53.194482Z",
     "iopub.status.busy": "2025-01-19T23:27:53.193482Z",
     "iopub.status.idle": "2025-01-19T23:28:41.239239Z",
     "shell.execute_reply": "2025-01-19T23:28:41.239239Z",
     "shell.execute_reply.started": "2025-01-19T23:27:53.194482Z"
    },
    "id": "WljAN9tMg5uU",
    "outputId": "8d6a1edf-462d-4cfc-8a0b-b8b28abc2762",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7c44ed3c24420c844087875b57986d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c6a4488e7d4fa798eb7a6a1469e666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "plt5_tokenizer = AutoTokenizer.from_pretrained(\"allegro/plt5-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = plt5_tokenizer(examples[\"text\"])\n",
    "    labels = plt5_tokenizer(text_target=examples[\"labels\"])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = datasets.map(preprocess_function, batched=False)#Trzeba dać batched = False, inaczej daje mi błąd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlSHE98SIFjv"
   },
   "source": [
    "Sprawdźmy jak dane wyglądają po tokenizacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:28:45.929034Z",
     "iopub.status.busy": "2025-01-19T23:28:45.929034Z",
     "iopub.status.idle": "2025-01-19T23:28:45.942712Z",
     "shell.execute_reply": "2025-01-19T23:28:45.942712Z",
     "shell.execute_reply.started": "2025-01-19T23:28:45.929034Z"
    },
    "id": "z3IM-Cd1IEba",
    "outputId": "036c7e0d-412d-4d43-e579-86d175b598fd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'labels', 'input_ids', 'attention_mask'])\n",
      "[21584, 291, 639, 402, 11586, 292, 23822, 267, 1269, 8741, 280, 24310, 42404, 305, 373, 1525, 15643, 291, 2958, 273, 19605, 6869, 271, 298, 2256, 7465, 394, 540, 2142, 259, 17542, 13760, 10331, 9511, 322, 31220, 261, 358, 348, 267, 7243, 430, 470, 271, 39908, 20622, 2178, 18204, 308, 8439, 2451, 259, 1974, 455, 540, 2142, 1283, 272, 994, 525, 259, 15697, 1978, 267, 264, 644, 259, 14988, 19434, 265, 1109, 287, 274, 357, 259, 21308, 264, 525, 259, 35197, 305, 265, 793, 823, 259, 25318, 2750, 4724, 31015, 21207, 4162, 40335, 18058, 259, 274, 4862, 7030, 261, 5269, 259, 658, 497, 261, 6971, 1890, 35042, 267, 266, 3260, 644, 259, 14988, 19434, 1187, 20919, 284, 27584, 19605, 1230, 2555, 259, 12531, 7278, 3845, 8726, 10486, 1187, 10676, 261, 996, 347, 260, 2548, 2142, 525, 259, 15697, 1978, 309, 27648, 31887, 19605, 259, 274, 4931, 36525, 37011, 4162, 10036, 7141, 265, 6340, 266, 465, 346, 269, 3648, 4383, 6704, 294, 465, 567, 2142, 454, 1]\n",
      "[39908, 20622, 2178, 18204, 308, 8439, 2451, 1]\n",
      "165\n",
      "8\n",
      "{'text': 'Pytanie: Co było powodem powrócenia konceptu porozumieniu monachijskiego? Kontekst: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942).', 'labels': [39908, 20622, 2178, 18204, 308, 8439, 2451, 1], 'input_ids': [21584, 291, 639, 402, 11586, 292, 23822, 267, 1269, 8741, 280, 24310, 42404, 305, 373, 1525, 15643, 291, 2958, 273, 19605, 6869, 271, 298, 2256, 7465, 394, 540, 2142, 259, 17542, 13760, 10331, 9511, 322, 31220, 261, 358, 348, 267, 7243, 430, 470, 271, 39908, 20622, 2178, 18204, 308, 8439, 2451, 259, 1974, 455, 540, 2142, 1283, 272, 994, 525, 259, 15697, 1978, 267, 264, 644, 259, 14988, 19434, 265, 1109, 287, 274, 357, 259, 21308, 264, 525, 259, 35197, 305, 265, 793, 823, 259, 25318, 2750, 4724, 31015, 21207, 4162, 40335, 18058, 259, 274, 4862, 7030, 261, 5269, 259, 658, 497, 261, 6971, 1890, 35042, 267, 266, 3260, 644, 259, 14988, 19434, 1187, 20919, 284, 27584, 19605, 1230, 2555, 259, 12531, 7278, 3845, 8726, 10486, 1187, 10676, 261, 996, 347, 260, 2548, 2142, 525, 259, 15697, 1978, 309, 27648, 31887, 19605, 259, 274, 4931, 36525, 37011, 4162, 10036, 7141, 265, 6340, 266, 465, 346, 269, 3648, 4383, 6704, 294, 465, 567, 2142, 454, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "▁Pytanie|:|▁Co|▁było|▁powodem|▁po|wróceni|a|▁kon|cept|u|▁porozumieniu|▁monachijski|ego|?|▁Kon|tekst|:|▁Projekt|y|▁konfederacji|▁zaczęły|▁się|▁za|łam|ywać|▁5|▁sierpnia|▁1942|.|▁Ponownie|▁wróciła|▁kwestia|▁mon|ach|ijska|,|▁co|▁u|a|ktyw|ni|ło|▁się|▁wymianą|▁listów|▁Ri|pka|▁–|▁Stro|ński|.|▁Natomiast|▁17|▁sierpnia|▁1942|▁doszło|▁do|▁spotkania|▁E|.|▁Bene|š|a|▁i|▁J|.|▁Masa|ryka|▁z|▁jednej|▁a|▁W|ł|.|▁Sikorskiego|▁i|▁E|.|▁Raczyński|ego|▁z|▁drugiej|▁strony|.|▁Polscy|▁dyplom|aci|▁zaproponowali|▁podpisanie|▁układu|▁konfederac|yjnego|.|▁W|▁następnym|▁miesiącu|,|▁tj|.|▁24|▁września|,|▁strona|▁polska|▁przesłał|a|▁na|▁ręce|▁J|.|▁Masa|ryka|▁projekt|▁deklaracji|▁o|▁przyszłej|▁konfederacji|▁obu|▁państw|.|▁Strona|▁cze|cho|słow|acka|▁projekt|▁przyjęła|,|▁lecz|▁już|▁w|▁listopadzie|▁1942|▁E|.|▁Bene|š|▁pod|ważył|▁ideę|▁konfederacji|.|▁W|▁zamian|▁zaproponowano|▁zawarcie|▁układu|▁sojusz|niczego|▁z|▁Polską|▁na|▁20|▁lat|▁(|form|alnie|▁nastąpiło|▁to|▁20|▁listopada|▁1942|).|</s>\n",
      "▁wymianą|▁listów|▁Ri|pka|▁–|▁Stro|ński|</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][0].keys())\n",
    "print(tokenized_datasets[\"train\"][0][\"input_ids\"])\n",
    "print(tokenized_datasets[\"train\"][0][\"labels\"])\n",
    "print(len(tokenized_datasets[\"train\"][0][\"input_ids\"]))\n",
    "print(len(tokenized_datasets[\"train\"][0][\"labels\"]))\n",
    "example = tokenized_datasets[\"train\"][0]\n",
    "print(example)\n",
    "print(\"|\".join(plt5_tokenizer.convert_ids_to_tokens(list(example[\"input_ids\"]))))\n",
    "print(\"|\".join(plt5_tokenizer.convert_ids_to_tokens(list(example[\"labels\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seBM6iumIY8x"
   },
   "source": [
    "Wykorzystywany przez nas model obsługuje teksty od długości do 512 sub-tokenów (w zasadzie ograniczenie to, w przeciwieństwie do modelu BERT nie wynika z samego modelu, więc teoretycznie moglibyśmy wykorzystywać dłuższe sekwencje, co jednak prowadzi do nadmiernej konsumpcji pamięci). Konieczne jest zatem sprawdzenie, czy w naszych danych nie ma tekstów o większej długości.\n",
    "\n",
    "## Zadanie 5 (0.5 punkt)\n",
    "\n",
    "Stwórz histogramy prezentujące rozkład długości (jako liczby tokenów) tekstów wejściowych (`input_ids`) oraz odpowiedzi (`labels`) dla zbioru treningowego. Zinterpretuj otrzymane wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:28:57.629202Z",
     "iopub.status.busy": "2025-01-19T23:28:57.628196Z",
     "iopub.status.idle": "2025-01-19T23:29:24.749589Z",
     "shell.execute_reply": "2025-01-19T23:29:24.749589Z",
     "shell.execute_reply.started": "2025-01-19T23:28:57.629202Z"
    },
    "id": "wSg4cZ2Xw9fJ",
    "outputId": "13a12abb-0d81-4032-fb83-4bedc1121f9f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum input length (input_ids): 1737\n",
      "Maximum label length (labels): 233\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "input_lengths = [len(example[\"input_ids\"]) for example in tokenized_datasets[\"train\"]]\n",
    "label_lengths = [len(example[\"labels\"]) for example in tokenized_datasets[\"train\"]]\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(input_lengths, bins=50, color='blue', alpha=0.7)\n",
    "plt.title(\"Distribution of Input Text Lengths (Input IDs)\")\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(label_lengths, bins=50, color='green', alpha=0.7)\n",
    "plt.title(\"Distribution of Answer Lengths (Labels)\")\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "max_input_length = max(input_lengths)\n",
    "max_label_length = max(label_lengths)\n",
    "\n",
    "print(f\"Maximum input length (input_ids): {max_input_length}\")\n",
    "print(f\"Maximum label length (labels): {max_label_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyaT0ebG0InY"
   },
   "source": [
    "Odpowiedzi są krótsze(token wise), co ma sens gdyż pytania oprócz samego pytania zawierają również kontekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTTrGUuvQQ63"
   },
   "source": [
    "Przyjmiemy założenie, że teksty wejściowe będą miały maksymalnie 256 tokenów, a większość odpowiedzi jest znacznie krótsza niż maksymalna długość, ograniczmy je do długości 32.\n",
    "\n",
    "W poniższym kodzie uwzględniamy również fakt, że przy obliczaniu funkcji straty nie interesuje nas wliczanie tokenów wypełnienia (PAD), gdyż ich udział byłby bardzo duży, a nie wpływają one w żaden pozytywny sposób na ocenę poprawności działania modelu.\n",
    "\n",
    "Konteksty (pytanie + kontekst odpowiedzi) ograniczamy do 256 tokenów, ze wzgędu na ograniczenia pamięciowe (zajętość pamięci dla modelu jest proporcjonalna do kwadratu długości tekstu). Dla kontekstów nie używamy parametru `padding`, ponieważ w trakcie treningu użyjemy modułu, który automatycznie doda padding, tak żeby wszystkie sekewncje miały długość najdłuższego tekstu w ramach paczki (moduł ten to `DataCollatorWithPadding`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:30:27.377954Z",
     "iopub.status.busy": "2025-01-19T23:30:27.376957Z",
     "iopub.status.idle": "2025-01-19T23:31:16.029108Z",
     "shell.execute_reply": "2025-01-19T23:31:16.027573Z",
     "shell.execute_reply.started": "2025-01-19T23:30:27.377954Z"
    },
    "id": "EpW4MNa1tGUV",
    "outputId": "8c0781d5-4a07-4552-be79-a0f16bf063d9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1966cfdfceb4074bb9ac94b820b216c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cba387c4514ef887ca566cd48d4983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    result = plt5_tokenizer(examples[\"text\"], truncation=True, max_length=256)\n",
    "    targets = plt5_tokenizer(\n",
    "        examples[\"labels\"], truncation=True, max_length=32, padding=True\n",
    "    )\n",
    "    input_ids = [\n",
    "        [(l if l != plt5_tokenizer.pad_token_id else -100) for l in e]\n",
    "        for e in targets[\"input_ids\"]\n",
    "    ]\n",
    "    result[\"labels\"] = input_ids\n",
    "    return result\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCLIl_cIyRxH"
   },
   "source": [
    "Następnie weryfkiujemy, czy przetworzone teksty mają poprawną postać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:31:19.151332Z",
     "iopub.status.busy": "2025-01-19T23:31:19.151332Z",
     "iopub.status.idle": "2025-01-19T23:31:19.159222Z",
     "shell.execute_reply": "2025-01-19T23:31:19.159222Z",
     "shell.execute_reply.started": "2025-01-19T23:31:19.151332Z"
    },
    "id": "bQ9i4ApASNIL",
    "outputId": "1ea928e9-6ff7-4441-87cd-1417809aba95",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'labels', 'input_ids', 'attention_mask'])\n",
      "[21584, 291, 639, 402, 11586, 292, 23822, 267, 1269, 8741, 280, 24310, 42404, 305, 373, 1525, 15643, 291, 2958, 273, 19605, 6869, 271, 298, 2256, 7465, 394, 540, 2142, 259, 17542, 13760, 10331, 9511, 322, 31220, 261, 358, 348, 267, 7243, 430, 470, 271, 39908, 20622, 2178, 18204, 308, 8439, 2451, 259, 1974, 455, 540, 2142, 1283, 272, 994, 525, 259, 15697, 1978, 267, 264, 644, 259, 14988, 19434, 265, 1109, 287, 274, 357, 259, 21308, 264, 525, 259, 35197, 305, 265, 793, 823, 259, 25318, 2750, 4724, 31015, 21207, 4162, 40335, 18058, 259, 274, 4862, 7030, 261, 5269, 259, 658, 497, 261, 6971, 1890, 35042, 267, 266, 3260, 644, 259, 14988, 19434, 1187, 20919, 284, 27584, 19605, 1230, 2555, 259, 12531, 7278, 3845, 8726, 10486, 1187, 10676, 261, 996, 347, 260, 2548, 2142, 525, 259, 15697, 1978, 309, 27648, 31887, 19605, 259, 274, 4931, 36525, 37011, 4162, 10036, 7141, 265, 6340, 266, 465, 346, 269, 3648, 4383, 6704, 294, 465, 567, 2142, 454, 1]\n",
      "[39908, 20622, 2178, 18204, 308, 8439, 2451, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "165\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][0].keys())\n",
    "print(tokenized_datasets[\"train\"][0][\"input_ids\"])\n",
    "print(tokenized_datasets[\"train\"][0][\"labels\"])\n",
    "print(len(tokenized_datasets[\"train\"][0][\"input_ids\"]))\n",
    "print(len(tokenized_datasets[\"train\"][0][\"labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEqhSrxLAwCH"
   },
   "source": [
    "Dla problemu odpowiadania na pytania potrzebować będziemy innego pre-trenowanego modelu oraz innego przygotowania danych. Jako model bazowy wykrzystamy polski wariant modelu T5 - [plT5](https://huggingface.co/allegro/plt5-base). Model ten trenowany był w zadaniu *span corruption*, czyli zadani polegającym na usunięciu fragmentu tekstu. Model na wejściu otrzymywał tekst z pominiętymi pewnymi fragmentami, a na wyjściu miał odtwarzać te fragmenty. Oryginalny model T5 dodatkowo pretrenowany był na kilku konkretnych zadaniach z zakresu NLP (w tym odpowiadaniu na pytania). W wariancie plT5 nie przeprowadzono jednak takiego dodatkowego procesu.\n",
    "\n",
    "Poniżej ładujemy model dla zadania, w którym model generuje tekst na podstawie innego tekstu (tzn. jest to zadanie zamiany tekstu na tekst, po angielsku zwanego też *Sequence-to-Sequence*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:31:25.045957Z",
     "iopub.status.busy": "2025-01-19T23:31:25.045957Z",
     "iopub.status.idle": "2025-01-19T23:32:02.397030Z",
     "shell.execute_reply": "2025-01-19T23:32:02.397030Z",
     "shell.execute_reply.started": "2025-01-19T23:31:25.045957Z"
    },
    "id": "ZvEOsWlAiWOu",
    "outputId": "812ff367-a00d-490e-d522-7629a9e4d47d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a2c87abd284c0a8bc515deab8c4269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allegro/plt5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UhNiDor4CSa"
   },
   "source": [
    "## Trening modelu QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TWCljD_yb0E"
   },
   "source": [
    "Ostatnim krokiem przed uruchomieniem treningu jest zdefiniowanie metryk, wskazujacych jak model radzi sobie z problemem. Wykorzystamy dwie metryki:\n",
    "* *exact match* - która sprawdza dokładne dopasowanie odpowiedzi do wartości referencyjnej, metryka ta jest bardzo restrykcyjna, ponieważ pojedynczy znak będzie powodował, że wartość będzie niepoprawna,\n",
    "* *blue score* - metryka uwzględniająca częściowe dopasowanie pomiędzy odpowiedzią a wartością referencyjną, najczęściej używana jest do oceny maszynowego tłumaczenia tekstu, ale może być również przydatna w ocenie wszelkich zadań, w których generowany jest tekst.\n",
    "\n",
    "Wykorzystujemy bibilotekę `evaluate`, która zawiera definicje obu metryk.\n",
    "\n",
    "Przy konwersji identyfikatorów tokenów na tekstu zamieniamy również z powroten tokeny o wartości -100 na identyfikatory paddingu. W przeciwnym razie dostaniemy błąd o nieistniejącym identyfikatorze tokenu.\n",
    "\n",
    "W procesie treningu pokazujemy również różnicę między jedną wygenerowaną oraz prawdziwą odpowiedzią dla zbioru ewaluacyjnego. W ten sposób możemy śledzić co rzeczywiście dzieje się w modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:32:04.604860Z",
     "iopub.status.busy": "2025-01-19T23:32:04.603866Z",
     "iopub.status.idle": "2025-01-19T23:32:12.349037Z",
     "shell.execute_reply": "2025-01-19T23:32:12.348025Z",
     "shell.execute_reply.started": "2025-01-19T23:32:04.604860Z"
    },
    "id": "bcjDjmjT2rVm",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2e4f45f78b4a50b0a96bd342949479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54613aefb78457a87952063d534349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5d08e1030b4cb1b2447c9e4f8fe3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be7cc1c896148ea985d25d04f41aa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "exact = evaluate.load(\"exact_match\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.where(predictions != -100, predictions, plt5_tokenizer.pad_token_id)\n",
    "    decoded_preds = plt5_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, plt5_tokenizer.pad_token_id)\n",
    "    decoded_labels = plt5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    print(\"prediction: \" + decoded_preds[0])\n",
    "    print(\"reference : \" + decoded_labels[0])\n",
    "\n",
    "    result = exact.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {**result, **bleu.compute(predictions=decoded_preds, references=decoded_labels)}\n",
    "    del result[\"precisions\"]\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != plt5_tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_49SDmpy5yo"
   },
   "source": [
    "## Zadanie 6 (0.5 punkty)\n",
    "\n",
    "Korzystając z klasy Seq2SeqTrainingArguments zdefiniuj następujące parametry trenignu:\n",
    "* inny katalog z wynikami\n",
    "* liczba epok: 3\n",
    "* wielkość paczki: 16\n",
    "* ewaluacja co 100 kroków,\n",
    "* szybkość uczenia: 1e-4\n",
    "* optymalizator: adafactor\n",
    "* maksymalna długość generowanej odpowiedzi: 32,\n",
    "* akumulacja wyników ewaluacji: 4\n",
    "* generowanie wyników podczas ewaluacji\n",
    "\n",
    "**W treningu nie używamy optymalizacji FP16!** Jej użycie spowoduje, że model nie będzie się trenował. Jeśli chcesz użyć optymalizacji, to możesz skorzystać z **BF16**.\n",
    "\n",
    "Argumenty powinny również wskazywać, że przeprowadzoany jest proces uczenia i ewaluacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:33:39.675028Z",
     "iopub.status.busy": "2025-01-19T23:33:39.675028Z",
     "iopub.status.idle": "2025-01-19T23:33:39.691183Z",
     "shell.execute_reply": "2025-01-19T23:33:39.691183Z",
     "shell.execute_reply.started": "2025-01-19T23:33:39.675028Z"
    },
    "id": "t4fTGCQ5yWc-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',             \n",
    "    num_train_epochs=3,                \n",
    "    per_device_train_batch_size=16,     \n",
    "    evaluation_strategy=\"steps\",       \n",
    "    eval_steps=100,                     \n",
    "    learning_rate=1e-4,                \n",
    "    optim=\"adafactor\",                  \n",
    "    gradient_accumulation_steps=4,     \n",
    "    generation_max_length=32,           \n",
    "    fp16=False,                         \n",
    "    bf16=True,                          \n",
    "    logging_dir='./logs',               \n",
    "    logging_steps=100,                  \n",
    "    load_best_model_at_end=True        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1wc95I3zrEC"
   },
   "source": [
    "## Zadanie 7 (0.5 punktu)\n",
    "\n",
    "Utwórz obiekt trenujący `Seq2SeqTrainer`, za pomocą którego będzie trenowany model odpowiadający na pytania.\n",
    "\n",
    "Obiekt ten powinien:\n",
    "* wykorzystywać model `plt5-base`,\n",
    "* wykorzystywać zbiór `train` do treningu,\n",
    "* wykorzystawać zbiór `dev` do evaluacji,\n",
    "* wykorzystać klasę batchującą (`data_collator`) o nazwie `DataCollatorWithPadding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:05:20.769322Z",
     "start_time": "2022-12-20T14:05:20.344307Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-19T23:35:35.251727Z",
     "iopub.status.busy": "2025-01-19T23:35:35.251727Z",
     "iopub.status.idle": "2025-01-19T23:35:39.922866Z",
     "shell.execute_reply": "2025-01-19T23:35:39.922866Z",
     "shell.execute_reply.started": "2025-01-19T23:35:35.251727Z"
    },
    "id": "X-l-Phk6zkvL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "plt5_tokenizer = AutoTokenizer.from_pretrained(\"allegro/plt5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allegro/plt5-base\")\n",
    "\n",
    "train_dataset = datasets[\"train\"]\n",
    "dev_dataset = datasets[\"dev\"]\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=plt5_tokenizer)\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=plt5_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30ng1TNCFoBM",
    "outputId": "e4bfcd0c-6cd6-448f-ab43-85e22eeeffc3"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir gdrive/MyDrive/poquad/output_qa/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pyrQ4m70WE6"
   },
   "source": [
    "Mając przygotowane wszystkie dane wejściowe możemy rozpocząć proces treningu.\n",
    "\n",
    "**Uwaga**: proces treningu na Google Colab z wykorzystaniem akceleratora zajmuje ok. 3 godziny. Uruchomienie treningu na CPU może trwać ponad 1 dzień!\n",
    "\n",
    "Możesz pominąć ten proces i w kolejnych krokach wykorzystać gotowy model `apohllo/plt5-base-poquad`, który znajduje się w repozytorium Hugginface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:38:22.650768Z",
     "iopub.status.busy": "2025-01-19T23:38:22.650768Z",
     "iopub.status.idle": "2025-01-19T23:38:22.654765Z",
     "shell.execute_reply": "2025-01-19T23:38:22.654765Z",
     "shell.execute_reply.started": "2025-01-19T23:38:22.650768Z"
    },
    "id": "CVew4vRlhyVP",
    "outputId": "7d0bf7c2-6e68-40fe-de05-8ebd03acfc76",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zamiast tego uzyje gotowego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3-k_ctqvwmf"
   },
   "source": [
    "## Zadanie 8 (1.5 punkt)\n",
    "\n",
    "Korzystając z wywołania `generate` w modelu, wygeneruj odpowiedzi dla 1 kontekstu i 10 pytań dotyczących tego kontekstu. Pamiętaj aby zamienić identyfikatory tokenów na ich treść. Możesz do tygo wykorzystać wywołanie `decode` z tokenizera.\n",
    "\n",
    "Jeśli w poprzednim punkcie nie udało Ci się wytrenować modelu, możesz skorzystać z modelu `apohllo/plt5-base-poquad`.\n",
    "\n",
    "Oceń wyniki (odpowiedzi) generowane przez model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:46:57.062234Z",
     "iopub.status.busy": "2025-01-19T23:46:57.062234Z",
     "iopub.status.idle": "2025-01-19T23:47:03.025372Z",
     "shell.execute_reply": "2025-01-19T23:47:03.024366Z",
     "shell.execute_reply.started": "2025-01-19T23:46:57.062234Z"
    },
    "id": "a4BuKkoPbEtn",
    "outputId": "161e346a-c7b0-4891-f13a-61b190f70226",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Bardziej trwałe są karbokationy o wyższej czy niższej rzędowości?\n",
      "Answer: niższej\n",
      "\n",
      "Question: Czy AGH jest lesze od UJ?\n",
      "Answer: nie\n",
      "\n",
      "Question: Czy obecność pierściennia aromatycznego działa stabiliząco na karbokation?\n",
      "Answer: tak\n",
      "\n",
      "Question: Nad jakim morzem leży Polska?\n",
      "Answer: nad Morzem Śródziemnym\n",
      "\n",
      "Question: Czy P=NP?\n",
      "Answer: tak\n",
      "\n",
      "Question: W któym roku otwarto wydział Informatyki AGH?\n",
      "Answer: w 2014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"apohllo/plt5-base-poquad\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"apohllo/plt5-base-poquad\")\n",
    "\n",
    "\n",
    "Q1=\"Bardziej trwałe są karbokationy o wyższej czy niższej rzędowości?\"\n",
    "Q2=\"Czy AGH jest lesze od UJ?\"\n",
    "Q3=\"Czy obecność pierściennia aromatycznego działa stabiliząco na karbokation?\"\n",
    "\n",
    "Q4=\"Nad jakim morzem leży Polska?\"\n",
    "Q5=\"Czy P=NP?\"\n",
    "Q6=\"W któym roku otwarto wydział Informatyki AGH?\"\n",
    "\n",
    "questions=[Q1,Q2,Q3,Q4,Q5,Q6]\n",
    "\n",
    "\n",
    "generated_answers = []\n",
    "for question in questions:\n",
    "    input_text = f\"Pytanie: {question} Kontekst: {context}\"\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    output = model.generate(inputs['input_ids'])\n",
    "    \n",
    "    decoded_answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    generated_answers.append(decoded_answer)\n",
    "\n",
    "\n",
    "for i, answer in enumerate(generated_answers):\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FArrKA6E0ix3"
   },
   "source": [
    "Generalnie odpowiedzi sa po polsku i w miarę są poprawne gramtycznie, natomiast wszystkie sa błędnie poza, poza tą o stabilizującym działaniu pierscieni aromatycznych na karbiokation :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9mN-0PiFoBN"
   },
   "source": [
    "# Zadanie dodatkowe (2 punkty)\n",
    "\n",
    "Stworzenie pełnego rozwiązania w zakresie odpowiadania na pytania wymaga również znajdowania kontekstów, w których może pojawić się pytanie.\n",
    "\n",
    "Obenie istnieje coraz więcej modeli neuronalnych, które bardzo dobrze radzą sobie ze znajdowaniem odpowiednich tekstów. Również dla języka polskiego następuje tutaj istotny postęp. Powstała m.in. [strona śledząca postępy w tym zakresie](https://huggingface.co/spaces/sdadas/pirb).\n",
    "\n",
    "Korzystając z informacji na tej stronie wybierz jeden z modeli do wyszukiwania kontekstów (najlepiej o rozmiarze `base` lub `small`). Zamień konteksty występujące w zbiorze PoQuAD na reprezentacje wektorowe. To samo zrób z pytaniami występującymi w tym zbiorze. Dla każdego pytania znajdź kontekst, który według modelu najlepiej odpowiada na zadane pytanie. Do znalezienia kontekstu oblicz iloczyn skalarny pomiędzy reprezentacją pytania oraz wszystkimi kontekstami ze zbioru. Następnie uruchom model generujący odpowiedź na znalezionym kontekście. Porównaj wyniki uzyskiwane w ten sposób, z wynikami, gdy poprawny kontekst jest znany.\n",
    "\n",
    "W celu przyspieszenie obliczeń możesz zmniejszyć liczbę pytań i odpowiadających im kontekstów. Pamiętaj jednak, żeby liczba kontekstów była odpowiednio duża (sugerowana wartość min. to 1000 kontekstów), tak żeby znalezienie kontekstu nie było trywialne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyiLVOPfFoBN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "763px",
    "left": "10px",
    "top": "150px",
    "width": "294.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
